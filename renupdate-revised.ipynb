{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09526afd-c48e-41d1-83e7-9f45953f4cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      " {\n",
      "  \"EIS_DIR\": \"C:\\\\Users\\\\tmgon\\\\OneDrive - Edith Cowan University (1)\\\\00 - Megallan Power\\\\NMC Batteries Warwick Station\\\\NMC\\\\DIB_Data\\\\.matfiles\\\\EIS_Test\",\n",
      "  \"CAP_DIR\": \"C:\\\\Users\\\\tmgon\\\\OneDrive - Edith Cowan University (1)\\\\00 - Megallan Power\\\\NMC Batteries Warwick Station\\\\NMC\\\\DIB_Data\\\\.matfiles\\\\Capacity_Check\",\n",
      "  \"MODEL_DIR\": \"models_eis_phase2_phys\",\n",
      "  \"EIS_TEST_FILE\": \"C:\\\\Users\\\\tmgon\\\\OneDrive - Edith Cowan University (1)\\\\00 - Megallan Power\\\\NMC Batteries Warwick Station\\\\NMC\\\\TestFile\\\\Mazda-Battery-Cell5.xlsx\",\n",
      "  \"F_MIN\": 0.01,\n",
      "  \"F_MAX\": 10000.0,\n",
      "  \"N_FREQ\": 60,\n",
      "  \"TEST_FRAC\": 0.2,\n",
      "  \"RANDOM_STATE\": 42,\n",
      "  \"USE_PCA_SOC\": true,\n",
      "  \"PCA_SOC_COMPONENTS\": 25,\n",
      "  \"USE_PCA_SOH\": false,\n",
      "  \"PCA_SOH_COMPONENTS\": 30,\n",
      "  \"INCLUDE_RAW_RE_IM\": true,\n",
      "  \"INCLUDE_BASICS\": true,\n",
      "  \"INCLUDE_F_FEATS\": true,\n",
      "  \"INCLUDE_PHYSICAL\": true,\n",
      "  \"INCLUDE_DRT\": true,\n",
      "  \"INCLUDE_BAND_STATS\": true,\n",
      "  \"INCLUDE_DIFF_SLOPES\": true,\n",
      "  \"DRT_POINTS\": 60,\n",
      "  \"DRT_TAU_MIN\": 0.0001,\n",
      "  \"DRT_TAU_MAX\": 10000.0,\n",
      "  \"DRT_LAMBDA\": 0.01,\n",
      "  \"REFINE_SOH_WITH_CAPACITY\": true,\n",
      "  \"MAX_GPR_TRAIN_SAMPLES\": 3500,\n",
      "  \"INCLUDE_NORMALIZED_SHAPE_MODEL\": true,\n",
      "  \"NORMALIZE_SHAPE_BY_HF_RE\": true,\n",
      "  \"ENSEMBLE_SOH\": true,\n",
      "  \"DECISION_SOH_PERCENT\": 50.0,\n",
      "  \"ILLUSTRATIVE_MIN_SOH\": 40.0,\n",
      "  \"CPP_ROLLING_WINDOW\": 5,\n",
      "  \"CPP_MIN_POINTS\": 6,\n",
      "  \"CPP_FALLBACK\": 20.0,\n",
      "  \"TEST_TEMPERATURE_OVERRIDE\": 25.0,\n",
      "  \"FORCE_RETRAIN\": false,\n",
      "  \"SAVE_FEATURE_TABLE\": true,\n",
      "  \"VERBOSE\": true,\n",
      "  \"FEATURE_VERSION\": 9,\n",
      "  \"PLOT_EXPONENT\": 1.25\n",
      "}\n",
      "[LOAD] Using bundle → models_eis_phase2_phys\\eis_soc_soh_phys_models.joblib\n",
      "{\n",
      "  \"file\": \"C:\\\\Users\\\\tmgon\\\\OneDrive - Edith Cowan University (1)\\\\00 - Megallan Power\\\\NMC Batteries Warwick Station\\\\NMC\\\\TestFile\\\\Mazda-Battery-Cell5.xlsx\",\n",
      "  \"parsed_metadata\": null,\n",
      "  \"predicted_SoC\": 5,\n",
      "  \"SoC_probabilities\": {\n",
      "    \"5\": 0.43468452380952394,\n",
      "    \"20\": 0.17007440476190472,\n",
      "    \"50\": 0.1409032738095238,\n",
      "    \"70\": 0.14718749999999997,\n",
      "    \"95\": 0.10715029761904762\n",
      "  },\n",
      "  \"predicted_SoH_percent\": 90.34750000003794,\n",
      "  \"SoH_std_estimate\": 3.0,\n",
      "  \"cycles_per_percent_used\": 20.0,\n",
      "  \"cycles_to_target\": 806.9500000007588,\n",
      "  \"cycles_to_lower\": 1006.9500000007588,\n",
      "  \"decision_threshold_percent\": 50.0,\n",
      "  \"lower_threshold_percent\": 40.0,\n",
      "  \"feature_version\": 9,\n",
      "  \"soh_model_chosen\": \"gpr_raw\"\n",
      "}\n",
      "[PLOT]  models_eis_phase2_phys\\Mazda-Battery-Cell5_projection.png\n",
      "[JSON]  models_eis_phase2_phys\\Mazda-Battery-Cell5_prediction.json\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# Unified EIS Training + Inference + Dynamic RUL  (v9 – single file)\n",
    "# ======================================================================\n",
    "#   • Accepts ONE EIS test file (cfg.EIS_TEST_FILE or --test path)\n",
    "#   • Learns a data-driven calibration factor for the GP’s predictive σ\n",
    "#   • Caps SoH uncertainty to ≈3 percentage-points\n",
    "#   • Outputs the single most-likely SoC class\n",
    "#   • Back-compatible with legacy model bundles\n",
    "# ======================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import sys, argparse, json, math, random, re, warnings, joblib\n",
    "from dataclasses import dataclass, asdict\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.io import loadmat\n",
    "from scipy import linalg\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error, r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# 1. CONFIGURATION\n",
    "# =========================\n",
    "@dataclass\n",
    "class Config:\n",
    "    # ---------- adjust these four paths ----------\n",
    "    # --- local folders -------------------------------------------------\n",
    "    EIS_DIR: Path = Path(r\"C:\\Users\\tmgon\\OneDrive - Edith Cowan University (1)\\00 - Megallan Power\\NMC Batteries Warwick Station\\NMC\\DIB_Data\\.matfiles\\EIS_Test\")\n",
    "    CAP_DIR: Path = Path(r\"C:\\Users\\tmgon\\OneDrive - Edith Cowan University (1)\\00 - Megallan Power\\NMC Batteries Warwick Station\\NMC\\DIB_Data\\.matfiles\\Capacity_Check\")\n",
    "    MODEL_DIR: Path = Path(\"models_eis_phase2_phys\")\n",
    "    EIS_TEST_FILE: Path = Path(r\"C:\\Users\\tmgon\\OneDrive - Edith Cowan University (1)\\00 - Megallan Power\\NMC Batteries Warwick Station\\NMC\\TestFile\\Mazda-Battery-Cell5.xlsx\")\n",
    "\n",
    "    # spectrum grid\n",
    "    F_MIN: float = 1e-2; F_MAX: float = 1e4; N_FREQ: int = 60\n",
    "    # split & seeds\n",
    "    TEST_FRAC: float = 0.20; RANDOM_STATE: int = 42\n",
    "    # PCA\n",
    "    USE_PCA_SOC: bool = True;  PCA_SOC_COMPONENTS: int = 25\n",
    "    USE_PCA_SOH: bool = False; PCA_SOH_COMPONENTS: int = 30\n",
    "    # feature toggles\n",
    "    INCLUDE_RAW_RE_IM: bool = True\n",
    "    INCLUDE_BASICS: bool = True\n",
    "    INCLUDE_F_FEATS: bool = True\n",
    "    INCLUDE_PHYSICAL: bool = True\n",
    "    INCLUDE_DRT: bool = True\n",
    "    INCLUDE_BAND_STATS: bool = True\n",
    "    INCLUDE_DIFF_SLOPES: bool = True\n",
    "    # DRT\n",
    "    DRT_POINTS: int = 60; DRT_TAU_MIN: float = 1e-4; DRT_TAU_MAX: float = 1e4; DRT_LAMBDA: float = 1e-2\n",
    "    # SoH / RUL\n",
    "    REFINE_SOH_WITH_CAPACITY: bool = True\n",
    "    MAX_GPR_TRAIN_SAMPLES: int = 3500\n",
    "    INCLUDE_NORMALIZED_SHAPE_MODEL: bool = True; NORMALIZE_SHAPE_BY_HF_RE: bool = True\n",
    "    ENSEMBLE_SOH: bool = True\n",
    "    DECISION_SOH_PERCENT: float = 50.0; ILLUSTRATIVE_MIN_SOH: float = 40.0\n",
    "    CPP_ROLLING_WINDOW: int = 5; CPP_MIN_POINTS: int = 6; CPP_FALLBACK: float = 20.0\n",
    "    # misc\n",
    "    TEST_TEMPERATURE_OVERRIDE: Optional[float] = 25.0\n",
    "    FORCE_RETRAIN: bool = False          # set True first time\n",
    "    SAVE_FEATURE_TABLE: bool = True; VERBOSE: bool = True\n",
    "    FEATURE_VERSION: int = 9; PLOT_EXPONENT: float = 1.25\n",
    "\n",
    "cfg = Config()\n",
    "cfg.MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# 2. UTILITIES\n",
    "# =========================\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "set_seed(cfg.RANDOM_STATE)\n",
    "\n",
    "def to_jsonable(x):\n",
    "    if isinstance(x, Path): return str(x)\n",
    "    if isinstance(x, dict): return {k: to_jsonable(v) for k, v in x.items()}\n",
    "    if isinstance(x, (list, tuple)): return [to_jsonable(i) for i in x]\n",
    "    return x\n",
    "\n",
    "CANON_FREQ = np.geomspace(cfg.F_MAX, cfg.F_MIN, cfg.N_FREQ)\n",
    "\n",
    "# =========================\n",
    "# 3. REGEX & METADATA PARSERS\n",
    "# =========================\n",
    "EIS_META_PATTERN = re.compile(\n",
    "    r\"Cell(?P<CellID>\\d+)_(?P<SOH>80|85|90|95|100)SOH_(?P<Temp>\\d+)degC_(?P<SOC>\\d+)SOC_(?P<RealSOH>\\d+)\"\n",
    ")\n",
    "CAP_META_PATTERN = re.compile(\n",
    "    r\"Cell(?P<CellID>\\d+)_(?P<SOH>80|85|90|95|100)SOH_Capacity_Check_(?P<Temp>\\d+)degC_(?P<Cycle>\\d+)cycle\"\n",
    ")\n",
    "\n",
    "def parse_eis_metadata(stem:str)->Optional[Dict[str,Any]]:\n",
    "    m=EIS_META_PATTERN.search(stem)\n",
    "    if not m: return None\n",
    "    d=m.groupdict()\n",
    "    return {\"CellID\":f\"Cell{d['CellID']}\",\n",
    "            \"SOH_stage\":int(d[\"SOH\"]),\n",
    "            \"SOC\":int(d[\"SOC\"]),\n",
    "            \"Temp\":int(d[\"Temp\"]),\n",
    "            \"RealSOH_file\":int(d[\"RealSOH\"])/100.0}\n",
    "\n",
    "def parse_cap_metadata(stem:str)->Optional[Dict[str,Any]]:\n",
    "    m=CAP_META_PATTERN.search(stem)\n",
    "    if not m: return None\n",
    "    d=m.groupdict()\n",
    "    return {\"CellID\":f\"Cell{d['CellID']}\",\n",
    "            \"SOH_stage\":int(d[\"SOH\"]),\n",
    "            \"Temp\":int(d[\"Temp\"]),\n",
    "            \"CycleIndex\":int(d[\"Cycle\"])}\n",
    "\n",
    "# =========================\n",
    "# 4. LOW-LEVEL LOADERS\n",
    "# =========================\n",
    "def _find_matrix(mat_dict:dict):\n",
    "    for v in mat_dict.values():\n",
    "        if isinstance(v,np.ndarray) and v.ndim==2 and v.shape[1]>=3:\n",
    "            return v\n",
    "    return None\n",
    "\n",
    "def _interp_channel(freq_raw,y_raw,freq_target):\n",
    "    freq_raw=np.asarray(freq_raw,float); y_raw=np.asarray(y_raw,float)\n",
    "    if freq_raw[0] < freq_raw[-1]:\n",
    "        freq_raw=freq_raw[::-1]; y_raw=y_raw[::-1]\n",
    "    uniq,idx=np.unique(freq_raw,return_index=True)\n",
    "    if len(uniq)!=len(freq_raw):\n",
    "        order=np.argsort(idx); freq_raw=uniq[order]; y_raw=y_raw[idx][order]\n",
    "    f=interp1d(freq_raw,y_raw,bounds_error=False,\n",
    "               fill_value=(y_raw[0],y_raw[-1]),kind=\"linear\")\n",
    "    return f(freq_target)\n",
    "\n",
    "FREQ_CANDS=[\"frequency\",\"freq\",\"f\",\"hz\",\"frequency(hz)\",\"Frequency(Hz)\"]\n",
    "RE_CANDS  =[\"zreal\",\"re(z)\",\"re\",\"real\",\"z_re\",\"Zreal\",\"Re (ohm)\",\"Zreal (ohm)\"]\n",
    "IM_CANDS  =[\"-zimag\",\"zimag\",\"im\",\"imag\",\"z_im\",\"Zimag\",\"Zimag (ohm)\"]\n",
    "\n",
    "def _select_column(df:pd.DataFrame,cands:List[str])->Optional[str]:\n",
    "    low={c.lower():c for c in df.columns}\n",
    "    for c in cands:\n",
    "        if c.lower() in low: return low[c.lower()]\n",
    "    for c in cands:\n",
    "        for col in df.columns:\n",
    "            if c.lower() in col.lower(): return col\n",
    "    return None\n",
    "\n",
    "def load_mat_eis(path:Path):\n",
    "    arr=_find_matrix(loadmat(path))\n",
    "    if arr is None: raise ValueError(\"No EIS matrix\")\n",
    "    return arr[:,0].astype(float),arr[:,1].astype(float),arr[:,2].astype(float)\n",
    "\n",
    "def load_table_eis(path:Path):\n",
    "    df=pd.read_csv(path) if path.suffix.lower()==\".csv\" else pd.read_excel(path)\n",
    "    if df.empty: raise ValueError(\"Empty table\")\n",
    "    fcol=_select_column(df,FREQ_CANDS)\n",
    "    recol=_select_column(df,RE_CANDS); imcol=_select_column(df,IM_CANDS)\n",
    "    if recol is None or imcol is None: raise ValueError(\"Re/Im columns missing\")\n",
    "    re_vals=pd.to_numeric(df[recol],errors=\"coerce\").to_numpy()\n",
    "    im_vals=pd.to_numeric(df[imcol],errors=\"coerce\").to_numpy()\n",
    "    freq_vals=pd.to_numeric(df[fcol],errors=\"coerce\").to_numpy() if fcol else \\\n",
    "               np.geomspace(cfg.F_MAX,cfg.F_MIN,len(re_vals))\n",
    "    if np.nanmean(im_vals)>0: im_vals=-im_vals\n",
    "    return freq_vals,re_vals.astype(float),im_vals.astype(float)\n",
    "\n",
    "def load_any_inference(path:Path):\n",
    "    suf=path.suffix.lower()\n",
    "    if suf==\".mat\": return load_mat_eis(path)\n",
    "    if suf in (\".csv\",\".xls\",\".xlsx\"): return load_table_eis(path)\n",
    "    raise ValueError(f\"Unsupported ext {suf}\")\n",
    "\n",
    "# =========================\n",
    "# 5. FEATURE ENGINEERING\n",
    "# =========================\n",
    "def compute_F_features(freq,re_i,im_i):\n",
    "    neg=-im_i; k=int(np.argmax(neg))\n",
    "    F1,F2,F3=re_i[0],re_i[k],re_i[-1]\n",
    "    sc=np.where(np.sign(im_i[:-1])!=np.sign(im_i[1:]))[0]\n",
    "    F4=np.nan\n",
    "    if len(sc):\n",
    "        j=sc[0]; y0,y1=im_i[j],im_i[j+1]; w=-y0/(y1-y0+1e-12)\n",
    "        F4=re_i[j]+w*(re_i[j+1]-re_i[j])\n",
    "    F5=re_i[k]-F1 if k>0 else np.nan\n",
    "    F6=np.min(im_i)\n",
    "    F7=re_i[int(np.argmin(np.abs(freq-10)))]\n",
    "    return [F1,F2,F3,F4,F5,F6,F7]\n",
    "\n",
    "PHYSICAL_FEATURE_NAMES=[\"Rs\",\"Rct\",\"tau_peak\",\"warburg_sigma\",\"arc_quality\",\n",
    "                        \"phase_mean_mid\",\"phase_std_mid\",\"phase_min\",\"lf_slope_negIm\",\"norm_arc\"]\n",
    "\n",
    "def physical_features(freq,re_i,im_i):\n",
    "    neg=-im_i; k=int(np.argmax(neg))\n",
    "    Rs,Rpeak,Rlow=re_i[0],re_i[k],re_i[-1]\n",
    "    Rct=max(Rpeak-Rs,0); arc_diam=Rlow-Rs; norm_arc=arc_diam/(Rs+1e-9)\n",
    "    tau_peak=1/(2*math.pi*freq[k]) if freq[k]>0 else np.nan\n",
    "    K=min(10,len(freq)//3); warburg_sigma=np.nan\n",
    "    if K>=4:\n",
    "        ws=(2*np.pi*freq[-K:])**-0.5; rs=re_i[-K:]\n",
    "        if len(np.unique(ws))>2: warburg_sigma=float(np.polyfit(ws,rs,1)[0])\n",
    "    ph=np.arctan2(-im_i,re_i); mid=(freq>=1)&(freq<=100)\n",
    "    phase_mean=ph[mid].mean() if mid.sum()>2 else np.nan\n",
    "    phase_std =ph[mid].std()  if mid.sum()>2 else np.nan\n",
    "    lf=(freq<=1); lf_slope=np.nan\n",
    "    if lf.sum()>=4:\n",
    "        x=np.log10(freq[lf]); y=neg[lf]\n",
    "        lf_slope=float(np.polyfit(x,y,1)[0])\n",
    "    arc_q=(neg.max()-neg.min())/(abs(neg.mean())+1e-9)\n",
    "    return [Rs,Rct,tau_peak,warburg_sigma,arc_q,\n",
    "            phase_mean,phase_std,float(ph.min()),lf_slope,norm_arc]\n",
    "\n",
    "BANDS=[(1e4,1e3),(1e3,1e2),(1e2,10),(10,1),(1,1e-1),(1e-1,1e-2)]\n",
    "def band_stats(freq,re_i,im_i):\n",
    "    out=[]; freq=np.asarray(freq)\n",
    "    for hi,lo in BANDS:\n",
    "        m=(freq<=hi)&(freq>=lo)\n",
    "        if m.sum()>1:\n",
    "            z=np.hypot(re_i[m],im_i[m]); out+=[z.mean(),z.std()]\n",
    "        else:\n",
    "            out+=[np.nan,np.nan]\n",
    "    return out\n",
    "\n",
    "def diff_slopes(freq,re_i,im_i,segments=5):\n",
    "    logf=np.log10(freq); edges=np.linspace(logf.min(),logf.max(),segments+1); res=[]\n",
    "    for i in range(segments):\n",
    "        m=(logf>=edges[i])&(logf<=edges[i+1])\n",
    "        if m.sum()>=3:\n",
    "            res+=list(np.polyfit(logf[m],re_i[m],1)[:1])+\\\n",
    "                  list(np.polyfit(logf[m],-im_i[m],1)[:1])\n",
    "        else:\n",
    "            res+=[np.nan,np.nan]\n",
    "    return res\n",
    "\n",
    "DRT_FEATURE_NAMES=[\"drt_sum\",\"drt_mean_logtau\",\"drt_var_logtau\",\"drt_peak_tau\",\n",
    "                   \"drt_peak_gamma\",\"drt_frac_low_tau\",\"drt_frac_high_tau\"]\n",
    "\n",
    "def compute_drt(freq,re_i,im_i,tmin,tmax,n,lam):\n",
    "    w=2*np.pi*freq; tau=np.geomspace(tmax,tmin,n); WT=w[:,None]*tau[None,:]\n",
    "    Kre=1/(1+WT**2); Kim=-WT/(1+WT**2)\n",
    "    yre=re_i-re_i[0]; yim=im_i\n",
    "    Y=np.concatenate([yre,yim]); K=np.vstack([Kre,Kim])\n",
    "    A=K.T@K+lam*np.eye(n); b=K.T@Y\n",
    "    g=linalg.solve(A,b,assume_a='pos')\n",
    "    return tau,np.clip(g,0,None)\n",
    "\n",
    "def drt_features(freq,re_i,im_i):\n",
    "    try:\n",
    "        tau,gamma=compute_drt(freq,re_i,im_i,\n",
    "                              cfg.DRT_TAU_MIN,cfg.DRT_TAU_MAX,cfg.DRT_POINTS,cfg.DRT_LAMBDA)\n",
    "        logt=np.log10(tau); s=gamma.sum()+1e-12; w=gamma/s\n",
    "        mean=(w*logt).sum(); var=(w*(logt-mean)**2).sum()\n",
    "        p=int(np.argmax(gamma))\n",
    "        frac_low=w[logt<=np.median(logt)].sum()\n",
    "        return [s,mean,var,float(tau[p]),float(gamma[p]),frac_low,1-frac_low]\n",
    "    except Exception:\n",
    "        return [np.nan]*7\n",
    "\n",
    "def build_feature_vector(re_i,im_i,temp,freq,include_names=False):\n",
    "    parts=[]; names=[]\n",
    "    if cfg.INCLUDE_RAW_RE_IM:\n",
    "        parts+=[re_i,im_i]\n",
    "        names+=[f\"Re_{i}\" for i in range(len(re_i))]+[f\"Im_{i}\" for i in range(len(im_i))]\n",
    "    if cfg.INCLUDE_BASICS:\n",
    "        z=np.hypot(re_i,im_i)\n",
    "        basics=[re_i[0],re_i[-1],re_i[-1]-re_i[0],z.max(),z.mean(),z.std()]\n",
    "        parts.append(basics); names+=[\"hf_re\",\"lf_re\",\"arc_diam\",\"zmag_max\",\"zmag_mean\",\"zmag_std\"]\n",
    "    if cfg.INCLUDE_F_FEATS:\n",
    "        parts.append(compute_F_features(freq,re_i,im_i)); names+=[f\"F{i}\" for i in range(1,8)]\n",
    "    if cfg.INCLUDE_PHYSICAL:\n",
    "        parts.append(physical_features(freq,re_i,im_i)); names+=PHYSICAL_FEATURE_NAMES\n",
    "    if cfg.INCLUDE_BAND_STATS:\n",
    "        parts.append(band_stats(freq,re_i,im_i))\n",
    "        for i in range(len(BANDS)): names+= [f\"band{i}_mean\",f\"band{i}_std\"]\n",
    "    if cfg.INCLUDE_DIFF_SLOPES:\n",
    "        ds=diff_slopes(freq,re_i,im_i); parts.append(ds)\n",
    "        for i in range(len(ds)//2): names += [f\"slope_re_seg{i}\",f\"slope_negIm_seg{i}\"]\n",
    "    if cfg.INCLUDE_DRT:\n",
    "        parts.append(drt_features(freq,re_i,im_i)); names+=DRT_FEATURE_NAMES\n",
    "    parts.append([temp]); names+=[\"Temp_feat\"]\n",
    "    vec=np.concatenate(parts).astype(float)\n",
    "    vec=np.nan_to_num(vec,0,0,0)\n",
    "    return (vec,names) if include_names else vec\n",
    "\n",
    "def build_shape_normalized(re_i,im_i):\n",
    "    hf=re_i[0] if re_i[0]!=0 else 1.0\n",
    "    return re_i/hf, im_i/hf\n",
    "\n",
    "# =========================\n",
    "# 6. CAPACITY  →  CPP HELPERS\n",
    "# =========================\n",
    "def load_capacity_info(cap_dir:Path)->pd.DataFrame:\n",
    "    if not (cap_dir.exists() and cfg.REFINE_SOH_WITH_CAPACITY):\n",
    "        return pd.DataFrame()\n",
    "    recs=[]\n",
    "    for fp in cap_dir.rglob(\"*.mat\"):\n",
    "        meta=parse_cap_metadata(fp.stem)\n",
    "        if not meta: continue\n",
    "        try:\n",
    "            arr=_find_matrix(loadmat(fp))\n",
    "            col=np.argmax(np.abs(arr[-50:]).mean(axis=0))\n",
    "            cap=float(np.nanmax(arr[:,col]))\n",
    "            meta[\"MeasuredCapacity_Ah\"]=cap\n",
    "            recs.append(meta)\n",
    "        except Exception: pass\n",
    "    if not recs: return pd.DataFrame()\n",
    "    df=pd.DataFrame(recs)\n",
    "    ref=df.groupby(\"CellID\")[\"MeasuredCapacity_Ah\"].transform(\"max\")\n",
    "    df[\"NormCapacity\"]=df[\"MeasuredCapacity_Ah\"]/ref\n",
    "    df[\"SoH_percent\"]=df[\"NormCapacity\"]*100.0\n",
    "    return df\n",
    "\n",
    "def estimate_cpp_per_cell(cap_df:pd.DataFrame,window:int,min_pts:int)->Dict[str,float]:\n",
    "    cpp={}\n",
    "    for cid,grp in cap_df.groupby(\"CellID\"):\n",
    "        g=grp.sort_values(\"CycleIndex\")\n",
    "        if g.shape[0]<min_pts: continue\n",
    "        tail=g.tail(window)\n",
    "        x,y=tail[\"CycleIndex\"].values,tail[\"SoH_percent\"].values\n",
    "        if len(np.unique(x))<2: continue\n",
    "        slope=np.polyfit(x,y,1)[0]\n",
    "        if slope>=-1e-6: continue\n",
    "        cpp[cid]=1/abs(slope)\n",
    "    return cpp\n",
    "\n",
    "def build_cpp_map(df:pd.DataFrame):\n",
    "    if df.empty: return {},cfg.CPP_FALLBACK\n",
    "    cpp_map=estimate_cpp_per_cell(df, cfg.CPP_ROLLING_WINDOW, cfg.CPP_MIN_POINTS)\n",
    "    global_cpp=float(np.median(list(cpp_map.values()))) if cpp_map else cfg.CPP_FALLBACK\n",
    "    return cpp_map,global_cpp\n",
    "\n",
    "def get_cpp(meta:dict,cpp_map:Dict[str,float],global_cpp:float)->float:\n",
    "    if not meta: return global_cpp\n",
    "    return cpp_map.get(meta[\"CellID\"],global_cpp)\n",
    "\n",
    "# =========================\n",
    "# 7. DATASET HELPERS\n",
    "# =========================\n",
    "def cell_split_mask(meta_df:pd.DataFrame):\n",
    "    cells=meta_df.CellID.unique()\n",
    "    rng=np.random.default_rng(cfg.RANDOM_STATE)\n",
    "    n=max(1,int(len(cells)*cfg.TEST_FRAC))\n",
    "    val=rng.choice(cells,size=n,replace=False)\n",
    "    return meta_df.CellID.isin(val)\n",
    "\n",
    "def build_dataset(eis_dir:Path,cap_df:Optional[pd.DataFrame]):\n",
    "    files=sorted(eis_dir.rglob(\"*.mat\"))\n",
    "    if not files: raise FileNotFoundError(\"No .mat in EIS_DIR\")\n",
    "\n",
    "    f0,r0,i0=load_mat_eis(files[0])\n",
    "    re0=_interp_channel(f0,r0,CANON_FREQ)\n",
    "    im0=_interp_channel(f0,i0,CANON_FREQ)\n",
    "    _,feat_names=build_feature_vector(re0,im0,25.0,CANON_FREQ,include_names=True)\n",
    "\n",
    "    feats,rows,shape_feats=[],[],[]\n",
    "    for fp in tqdm(files,desc=\"Loading\"):\n",
    "        try:\n",
    "            f,r,i=load_mat_eis(fp)\n",
    "            re=_interp_channel(f,r,CANON_FREQ)\n",
    "            im=_interp_channel(f,i,CANON_FREQ)\n",
    "            meta=parse_eis_metadata(fp.stem)\n",
    "            if meta is None: continue\n",
    "            feats.append(build_feature_vector(re,im,meta[\"Temp\"],CANON_FREQ))\n",
    "            rows.append(meta)\n",
    "            if cfg.INCLUDE_NORMALIZED_SHAPE_MODEL and cfg.NORMALIZE_SHAPE_BY_HF_RE:\n",
    "                rn,in_=build_shape_normalized(re,im)\n",
    "                shape_feats.append(build_feature_vector(rn,in_,meta[\"Temp\"],CANON_FREQ))\n",
    "        except Exception as e:\n",
    "            if cfg.VERBOSE: print(f\"[Skip] {fp.name}: {e}\")\n",
    "\n",
    "    if not rows: raise RuntimeError(\"No valid spectra\")\n",
    "\n",
    "    X=np.vstack(feats)\n",
    "    X_shape=np.vstack(shape_feats) if shape_feats else None\n",
    "    meta_df=pd.DataFrame(rows)\n",
    "\n",
    "    if cfg.REFINE_SOH_WITH_CAPACITY and not cap_df.empty:\n",
    "        lookup=cap_df.set_index([\"CellID\",\"SOH_stage\"])[\"NormCapacity\"].to_dict()\n",
    "        meta_df[\"SoH_cont\"]=[\n",
    "            100*lookup.get((cid,stg),fallback)\n",
    "            for cid,stg,fallback in zip(meta_df.CellID,meta_df.SOH_stage,meta_df.RealSOH_file)\n",
    "        ]\n",
    "    else:\n",
    "        meta_df[\"SoH_cont\"]=meta_df[\"RealSOH_file\"]\n",
    "\n",
    "    y_soc=meta_df[\"SOC\"].values\n",
    "    y_soh=meta_df[\"SoH_cont\"].values\n",
    "\n",
    "    if cfg.SAVE_FEATURE_TABLE:\n",
    "        pd.concat([meta_df.reset_index(drop=True),\n",
    "                   pd.DataFrame(X,columns=feat_names)],\n",
    "                  axis=1).to_parquet(cfg.MODEL_DIR/\"training_features.parquet\",index=False)\n",
    "\n",
    "    return meta_df,X,(X_shape,feat_names),y_soc,y_soh\n",
    "\n",
    "# =========================\n",
    "# 8. TRAIN MODELS (incl. σ-calibration)\n",
    "# =========================\n",
    "def train_models(meta_df,X_raw,shape_bundle,y_soc,y_soh):\n",
    "    rng=np.random.default_rng(cfg.RANDOM_STATE)\n",
    "    X_shape,feat_names=shape_bundle\n",
    "    mask_val=cell_split_mask(meta_df)\n",
    "\n",
    "    # ---------- SoC ----------\n",
    "    soc_scal=StandardScaler(); X_soc=soc_scal.fit_transform(X_raw)\n",
    "    soc_pca=None\n",
    "    if cfg.USE_PCA_SOC:\n",
    "        soc_pca=PCA(n_components=min(cfg.PCA_SOC_COMPONENTS,X_soc.shape[1]-1),\n",
    "                    random_state=cfg.RANDOM_STATE)\n",
    "        X_soc=soc_pca.fit_transform(X_soc)\n",
    "    soc_model=RandomForestClassifier(\n",
    "        n_estimators=800,min_samples_leaf=2,class_weight=\"balanced\",\n",
    "        n_jobs=-1,random_state=cfg.RANDOM_STATE)\n",
    "    soc_model.fit(X_soc[~mask_val],y_soc[~mask_val])\n",
    "    if cfg.VERBOSE:\n",
    "        pv=soc_model.predict(X_soc[mask_val])\n",
    "        print(f\"[SoC] Acc={accuracy_score(y_soc[mask_val],pv):.3f}  \"\n",
    "              f\"F1={f1_score(y_soc[mask_val],pv,average='macro'):.3f}\")\n",
    "\n",
    "    # ---------- SoH GP ----------\n",
    "    soh_scal=StandardScaler(); Xs=soh_scal.fit_transform(X_raw)\n",
    "    soh_pca=None\n",
    "    if cfg.USE_PCA_SOH:\n",
    "        soh_pca=PCA(n_components=min(cfg.PCA_SOH_COMPONENTS,Xs.shape[1]-1),\n",
    "                    random_state=cfg.RANDOM_STATE)\n",
    "        Xs=soh_pca.fit_transform(Xs)\n",
    "\n",
    "    kernel=RBF(length_scale=np.ones(Xs.shape[1])*3.0,\n",
    "               length_scale_bounds=(1e-1,1e4))+WhiteKernel(noise_level=1e-2,\n",
    "                                                           noise_level_bounds=(1e-6,1e-1))\n",
    "    gpr=GaussianProcessRegressor(kernel=kernel,alpha=0,normalize_y=True,\n",
    "                                 random_state=cfg.RANDOM_STATE,n_restarts_optimizer=3)\n",
    "    idx=rng.choice(Xs.shape[0],size=min(cfg.MAX_GPR_TRAIN_SAMPLES,Xs.shape[0]),\n",
    "                   replace=False)\n",
    "    gpr.fit(Xs[idx],y_soh[idx])\n",
    "\n",
    "    mu_val,sig_val=gpr.predict(Xs[mask_val],return_std=True)\n",
    "    rmse=mean_squared_error(y_soh[mask_val],mu_val,squared=False)\n",
    "    sigma_fact=float(np.clip(rmse/(sig_val.mean()+1e-12),0.1,5.0))\n",
    "    r2_gpr=r2_score(y_soh[mask_val],mu_val)\n",
    "\n",
    "    # ---------- HGB fallback ----------\n",
    "    hgb=HistGradientBoostingRegressor(learning_rate=0.05,max_iter=500,\n",
    "                                      l2_regularization=1e-3,\n",
    "                                      random_state=cfg.RANDOM_STATE)\n",
    "    hgb.fit(Xs[~mask_val],y_soh[~mask_val])\n",
    "    r2_hgb=r2_score(y_soh[mask_val],hgb.predict(Xs[mask_val]))\n",
    "\n",
    "    soh_model,soh_name=(gpr,\"gpr_raw\") if r2_gpr>=r2_hgb else (hgb,\"hgb_raw\")\n",
    "\n",
    "    # ---------- shape-GP (optional) ----------\n",
    "    shape_scal=shape_pca=shape_model=None\n",
    "    if cfg.INCLUDE_NORMALIZED_SHAPE_MODEL and X_shape is not None:\n",
    "        shape_scal=StandardScaler(); Xsh=shape_scal.fit_transform(X_shape)\n",
    "        if cfg.USE_PCA_SOH:\n",
    "            shape_pca=PCA(n_components=min(cfg.PCA_SOH_COMPONENTS,Xsh.shape[1]-1),\n",
    "                          random_state=cfg.RANDOM_STATE)\n",
    "            Xsh=shape_pca.fit_transform(Xsh)\n",
    "        kernel_s=RBF(length_scale=np.ones(Xsh.shape[1])*3.0,\n",
    "                     length_scale_bounds=(1e-1,1e4))+WhiteKernel(noise_level=1e-2,\n",
    "                                                                 noise_level_bounds=(1e-6,1e-1))\n",
    "        shape_model=GaussianProcessRegressor(kernel=kernel_s,alpha=0,normalize_y=True,\n",
    "                                             random_state=cfg.RANDOM_STATE,n_restarts_optimizer=3)\n",
    "        idxs=rng.choice(Xsh.shape[0],size=min(cfg.MAX_GPR_TRAIN_SAMPLES,Xsh.shape[0]),\n",
    "                        replace=False)\n",
    "        shape_model.fit(Xsh[idxs],y_soh[idxs])\n",
    "\n",
    "    # ---------- bundle ----------\n",
    "    cov=np.cov(Xs.T); cov_inv=np.linalg.pinv(cov); center=Xs.mean(axis=0)\n",
    "\n",
    "    bundle={\n",
    "        \"soc_scaler\":soc_scal,\"soc_pca\":soc_pca,\"soc_model\":soc_model,\n",
    "        \"soh_scaler\":soh_scal,\"soh_pca\":soh_pca,\"soh_model\":soh_model,\n",
    "        \"soh_model_name\":soh_name,\n",
    "        \"shape_scaler\":shape_scal,\"shape_pca\":shape_pca,\"shape_model\":shape_model,\n",
    "        \"freq_grid\":CANON_FREQ,\"feature_version\":cfg.FEATURE_VERSION,\n",
    "        \"feature_manifest\":feat_names,\n",
    "        \"train_mahal\":{\"center\":center.tolist(),\"cov_inv\":cov_inv.tolist()},\n",
    "        \"soh_sigma_factor\":sigma_fact\n",
    "    }\n",
    "    joblib.dump(bundle,cfg.MODEL_DIR/\"eis_soc_soh_phys_models.joblib\")\n",
    "    return bundle\n",
    "\n",
    "# =========================\n",
    "# 9. FEATURISATION FOR INFERENCE\n",
    "# =========================\n",
    "def featurize_any(file_path:Path,bundle):\n",
    "    freq_grid=bundle[\"freq_grid\"]\n",
    "    meta=parse_eis_metadata(file_path.stem)\n",
    "\n",
    "    freq,re_raw,im_raw=load_any_inference(file_path)\n",
    "    re_i=_interp_channel(freq,re_raw,freq_grid)\n",
    "    im_i=_interp_channel(freq,im_raw,freq_grid)\n",
    "\n",
    "    temp=meta[\"Temp\"] if meta else cfg.TEST_TEMPERATURE_OVERRIDE or -1\n",
    "\n",
    "    vec=build_feature_vector(re_i,im_i,temp,freq_grid)\n",
    "\n",
    "    norm_vec=None\n",
    "    if cfg.INCLUDE_NORMALIZED_SHAPE_MODEL and bundle.get(\"shape_model\"):\n",
    "        rn,in_=build_shape_normalized(re_i,im_i)\n",
    "        norm_vec=build_feature_vector(rn,in_,temp,freq_grid)\n",
    "    return vec,norm_vec,meta\n",
    "\n",
    "# =========================\n",
    "# 10. INFERENCE FOR ONE FILE\n",
    "# =========================\n",
    "def predict_file(fp:Path,bundle,cpp_map,global_cpp):\n",
    "    vec,norm_vec,meta=featurize_any(fp,bundle)\n",
    "\n",
    "    # SoC\n",
    "    sc,bp,sm=bundle[\"soc_scaler\"],bundle.get(\"soc_pca\"),bundle[\"soc_model\"]\n",
    "    X=sc.transform(vec.reshape(1,-1)); X=bp.transform(X) if bp is not None else X\n",
    "    probs=sm.predict_proba(X)[0]; soc=int(sm.classes_[probs.argmax()])\n",
    "\n",
    "    # SoH\n",
    "    ss,sp,soh_m=bundle[\"soh_scaler\"],bundle.get(\"soh_pca\"),bundle[\"soh_model\"]\n",
    "    Xs=ss.transform(vec.reshape(1,-1)); Xs=sp.transform(Xs) if sp is not None else Xs\n",
    "    if isinstance(soh_m,GaussianProcessRegressor):\n",
    "        mu,sig=soh_m.predict(Xs,return_std=True)\n",
    "        soh=float(mu[0])\n",
    "        sd=float(sig[0])*bundle.get(\"soh_sigma_factor\",1.0)\n",
    "    else:\n",
    "        soh=float(soh_m.predict(Xs)[0]); sd=4.0\n",
    "    sd=float(np.clip(sd,0.1,3.0))\n",
    "\n",
    "    # optional ensemble\n",
    "    if cfg.ENSEMBLE_SOH and bundle.get(\"shape_model\") and norm_vec is not None:\n",
    "        shc,shp,shm=bundle[\"shape_scaler\"],bundle.get(\"shape_pca\"),bundle[\"shape_model\"]\n",
    "        Xn=shc.transform(norm_vec.reshape(1,-1)); Xn=shp.transform(Xn) if shp is not None else Xn\n",
    "        soh=0.5*(soh+float(shm.predict(Xn)[0]))\n",
    "\n",
    "    cpp=get_cpp(meta,cpp_map,global_cpp)\n",
    "    cyc_t=max((soh-cfg.DECISION_SOH_PERCENT)*cpp,0.0)\n",
    "    cyc_l=max((soh-cfg.ILLUSTRATIVE_MIN_SOH)*cpp,0.0)\n",
    "\n",
    "    return {\"file\":str(fp),\n",
    "            \"parsed_metadata\":meta,\n",
    "            \"predicted_SoC\":soc,\n",
    "            \"SoC_probabilities\":{int(c):float(p) for c,p in zip(sm.classes_,probs)},\n",
    "            \"predicted_SoH_percent\":soh,\n",
    "            \"SoH_std_estimate\":sd,\n",
    "            \"cycles_per_percent_used\":cpp,\n",
    "            \"cycles_to_target\":cyc_t,\n",
    "            \"cycles_to_lower\":cyc_l,\n",
    "            \"decision_threshold_percent\":cfg.DECISION_SOH_PERCENT,\n",
    "            \"lower_threshold_percent\":cfg.ILLUSTRATIVE_MIN_SOH,\n",
    "            \"feature_version\":bundle[\"feature_version\"],\n",
    "            \"soh_model_chosen\":bundle.get(\"soh_model_name\",\"raw\")}, cyc_t, cyc_l\n",
    "\n",
    "# =========================\n",
    "# 11. PLOT HELPER\n",
    "# =========================\n",
    "def build_projection(soh,cpp,lower,exp=None,n=160):\n",
    "    if soh<=lower or cpp<=0: return np.array([0]),np.array([soh])\n",
    "    total=(soh-lower)*cpp; cycs=np.linspace(0,total,n)\n",
    "    exp=cfg.PLOT_EXPONENT if exp is None else exp\n",
    "    curve=lower+(soh-lower)*(1-cycs/total)**exp\n",
    "    return cycs,curve\n",
    "\n",
    "def plot_projection(name,soh,sd,cyc_t,cyc_l,cpp,out):\n",
    "    if cyc_l<=0: return\n",
    "    cycs,curve=build_projection(soh,cpp,cfg.ILLUSTRATIVE_MIN_SOH)\n",
    "    plt.figure(figsize=(6.4,4))\n",
    "    plt.plot(cycs,curve,lw=2,label=\"Projected SoH\")\n",
    "    plt.axhline(cfg.DECISION_SOH_PERCENT,color=\"orange\",ls=\"--\")\n",
    "    plt.axhline(cfg.ILLUSTRATIVE_MIN_SOH,color=\"red\",ls=\":\")\n",
    "    plt.scatter([0],[soh],c=\"green\",s=55)\n",
    "    plt.text(0,soh+0.7,f\"±{sd:.2f}\",color=\"green\",fontsize=8)\n",
    "    if cyc_t>0:\n",
    "        plt.axvline(cyc_t,color=\"orange\",ls=\"-.\")\n",
    "    plt.scatter([cycs[-1]],[cfg.ILLUSTRATIVE_MIN_SOH],c=\"red\",s=50)\n",
    "    plt.xlabel(\"Remaining Cycles\"); plt.ylabel(\"SoH (%)\")\n",
    "    plt.title(f\"RUL Projection – {name}\")\n",
    "    plt.grid(alpha=0.35); plt.tight_layout(); plt.savefig(out,dpi=140); plt.close()\n",
    "\n",
    "# =========================\n",
    "# 12. LOAD (legacy shim)\n",
    "# =========================\n",
    "def load_bundle():\n",
    "    b=joblib.load(cfg.MODEL_DIR/\"eis_soc_soh_phys_models.joblib\")\n",
    "    if \"soc_scaler\" not in b:          # older bundles\n",
    "        b[\"soc_scaler\"]=b[\"scaler\"]; b[\"soh_scaler\"]=b[\"scaler\"]\n",
    "        b[\"soc_pca\"]=b.get(\"pca\"); b[\"soh_pca\"]=b.get(\"pca\")\n",
    "    return b\n",
    "\n",
    "# =========================\n",
    "# 13. MAIN\n",
    "# =========================\n",
    "def main(argv=None):\n",
    "    p=argparse.ArgumentParser(add_help=False)\n",
    "    p.add_argument(\"--test\",dest=\"test_file\")\n",
    "    args,_=p.parse_known_args([] if argv is None else argv)\n",
    "    if args.test_file:\n",
    "        cfg.EIS_TEST_FILE=Path(args.test_file)\n",
    "\n",
    "    assert cfg.EIS_DIR.exists(),  f\"EIS_DIR missing: {cfg.EIS_DIR}\"\n",
    "    if cfg.REFINE_SOH_WITH_CAPACITY:\n",
    "        assert cfg.CAP_DIR.exists(), f\"CAP_DIR missing: {cfg.CAP_DIR}\"\n",
    "\n",
    "    if cfg.VERBOSE:\n",
    "        print(\"Configuration:\\n\",json.dumps(to_jsonable(asdict(cfg)),indent=2))\n",
    "\n",
    "    cap_df=load_capacity_info(cfg.CAP_DIR)\n",
    "    cpp_map,global_cpp=build_cpp_map(cap_df)\n",
    "\n",
    "    bundle_path=cfg.MODEL_DIR/\"eis_soc_soh_phys_models.joblib\"\n",
    "    if bundle_path.exists() and not cfg.FORCE_RETRAIN:\n",
    "        bundle=load_bundle()\n",
    "        if cfg.VERBOSE: print(f\"[LOAD] Using bundle → {bundle_path}\")\n",
    "    else:\n",
    "        if cfg.VERBOSE: print(\"[TRAIN] Building dataset & training models …\")\n",
    "        meta_df,X,shape_bundle,y_soc,y_soh=build_dataset(cfg.EIS_DIR,cap_df)\n",
    "        bundle=train_models(meta_df,X,shape_bundle,y_soc,y_soh)\n",
    "\n",
    "    test_fp=cfg.EIS_TEST_FILE\n",
    "    if not test_fp.exists(): raise FileNotFoundError(test_fp)\n",
    "    result,cyc_t,cyc_l=predict_file(test_fp,bundle,cpp_map,global_cpp)\n",
    "\n",
    "    out_plot=cfg.MODEL_DIR/f\"{test_fp.stem}_projection.png\"\n",
    "    plot_projection(test_fp.stem,\n",
    "                    result[\"predicted_SoH_percent\"],\n",
    "                    result[\"SoH_std_estimate\"],\n",
    "                    result[\"cycles_to_target\"],\n",
    "                    result[\"cycles_to_lower\"],\n",
    "                    result[\"cycles_per_percent_used\"],\n",
    "                    out_plot)\n",
    "\n",
    "    out_json=cfg.MODEL_DIR/f\"{test_fp.stem}_prediction.json\"\n",
    "    with out_json.open(\"w\",encoding=\"utf-8\") as f: json.dump(result,f,indent=2)\n",
    "\n",
    "    print(json.dumps(result,indent=2))\n",
    "    print(f\"[PLOT]  {out_plot}\")\n",
    "    print(f\"[JSON]  {out_json}\\nDone.\")\n",
    "\n",
    "# =========================\n",
    "# 14. RUN\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    main([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b33917-6976-4134-ac58-b1a34771fc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRADIO] Loaded bundle → models_eis_phase2_phys\\eis_soc_soh_phys_models.joblib\n",
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ────────────────────────────────────────────────────────────────────────\n",
    "# Gradio demo – upload ONE EIS file → projection plot + predicted SoC\n",
    "# ────────────────────────────────────────────────────────────────────────\n",
    "import gradio as gr, tempfile, shutil\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings; warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# ---------- 1. one-time model / CPP setup ------------------------------\n",
    "cap_df   = load_capacity_info(cfg.CAP_DIR)\n",
    "cpp_map, global_cpp = build_cpp_map(cap_df) if not cap_df.empty else ({}, cfg.CPP_FALLBACK)\n",
    "\n",
    "bundle_path = cfg.MODEL_DIR / \"eis_soc_soh_phys_models.joblib\"\n",
    "if bundle_path.exists() and not cfg.FORCE_RETRAIN:\n",
    "    bundle = load_bundle()\n",
    "    print(f\"[GRADIO] Loaded bundle → {bundle_path}\")\n",
    "else:\n",
    "    print(\"[GRADIO] Training bundle – first run only …\")\n",
    "    meta_df, X_raw, shape_bundle, y_soc, y_soh = build_dataset(cfg.EIS_DIR, cap_df)\n",
    "    bundle = train_models(meta_df, X_raw, shape_bundle, y_soc, y_soh)\n",
    "\n",
    "# ---------- 2. helpers --------------------------------------------------\n",
    "HEADER_MD = \"\"\"\n",
    "### SoH prediction for NMC profile  \n",
    "Addressing *Electric Vehicle Battery Repurposing Challenges*, iMOVE Australia Limited, iMOVE CRC  \n",
    "*Prepared by Research Team, Centre for Green and Smart Energy Systems, Edith Cowan University (Joondalup)*\n",
    "\"\"\".strip()\n",
    "\n",
    "def metrics_md(bndl):\n",
    "    a, f1 = bndl.get(\"soc_acc\"), bndl.get(\"soc_f1\")\n",
    "    if a is None or f1 is None:\n",
    "        return \"_Accuracy / F1 not available (bundle predates metric storage)._\"\n",
    "    return f\"**Validation —  Acc&nbsp;=&nbsp;{a:.3f},  F1&nbsp;(macro)&nbsp;=&nbsp;{f1:.3f}**\"\n",
    "\n",
    "# ---------- 3. gradio callback -----------------------------------------\n",
    "def run_inference(uploaded_file):\n",
    "    tmp_path = Path(tempfile.gettempdir()) / Path(uploaded_file.name).name\n",
    "    shutil.copy(uploaded_file.name, tmp_path)\n",
    "\n",
    "    result, *_ = predict_file(tmp_path, bundle, cpp_map, global_cpp)\n",
    "\n",
    "    plot_path = cfg.MODEL_DIR / f\"{tmp_path.stem}_projection.png\"\n",
    "    plot_projection(\n",
    "        tmp_path.stem,\n",
    "        result[\"predicted_SoH_percent\"],\n",
    "        result[\"SoH_std_estimate\"],\n",
    "        result[\"cycles_to_target\"],\n",
    "        result[\"cycles_to_lower\"],\n",
    "        result[\"cycles_per_percent_used\"],\n",
    "        plot_path\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        Image.open(plot_path),             # RUL chart\n",
    "        int(result[\"predicted_SoC\"]),      # most-likely SoC\n",
    "        metrics_md(bundle)                 # model metrics\n",
    "    )\n",
    "\n",
    "# ---------- 4. build & launch UI ---------------------------------------\n",
    "demo = gr.Interface(\n",
    "    title=\"SoH prediction for NMC profile\",\n",
    "    description=HEADER_MD,\n",
    "    fn=run_inference,\n",
    "    inputs=gr.File(label=\"Upload EIS test file\"),\n",
    "    outputs=[\n",
    "        gr.Image(type=\"pil\", label=\"RUL projection\"),\n",
    "        gr.Number(label=\"Predicted SoC (%)\"),\n",
    "        gr.Markdown(label=\"Model metrics\")\n",
    "    ],\n",
    ")\n",
    "\n",
    "# no fixed port → avoids “port already in use”; share=False keeps it local\n",
    "demo.launch(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7b1e92-7888-4f64-870a-f121c84f9a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b2d515-7aa9-4a89-9dc1-679800a10b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "557bc796-a443-4c10-8907-8abd1a01c8d7",
   "metadata": {},
   "source": [
    "# Updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a10ed02-e57e-425f-a556-ca1fe3f5ebb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
