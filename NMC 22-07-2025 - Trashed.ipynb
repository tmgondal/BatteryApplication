{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0449f2ee-d9b1-4207-bb75-ee19a9297b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load spectra: 100%|██████████| 360/360 [00:00<00:00, 635.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SoC] accuracy: 0.9833333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           5     1.0000    0.9167    0.9565        12\n",
      "          20     1.0000    1.0000    1.0000        12\n",
      "          50     0.9231    1.0000    0.9600        12\n",
      "          70     1.0000    1.0000    1.0000        12\n",
      "          95     1.0000    1.0000    1.0000        12\n",
      "\n",
      "    accuracy                         0.9833        60\n",
      "   macro avg     0.9846    0.9833    0.9833        60\n",
      "weighted avg     0.9846    0.9833    0.9833        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 1 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 2 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 4 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 6 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 7 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 10 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 12 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 18 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 19 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 21 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 25 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 27 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 28 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 29 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 30 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 31 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 32 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 33 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 35 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 37 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 38 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 42 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 44 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 45 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 46 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 47 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 50 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 51 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 53 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 54 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 60 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 61 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 62 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 63 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 64 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 65 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 66 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 67 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 68 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 69 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 70 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 71 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 73 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 75 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 76 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 78 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 79 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 86 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 88 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 89 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 92 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 94 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 97 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 98 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 100 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 101 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 103 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 105 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 107 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 109 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 114 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 117 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 118 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tmgon\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 125 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoH] R² test = 0.994\n",
      "\n",
      " {\n",
      "  \"file\": \"Mazda-Battery-Cell1.xlsx\",\n",
      "  \"predicted_SoC\": 5,\n",
      "  \"SoC_probabilities\": {\n",
      "    \"5\": 0.34958333333333336,\n",
      "    \"20\": 0.30333333333333334,\n",
      "    \"50\": 0.04541666666666666,\n",
      "    \"70\": 0.12333333333333334,\n",
      "    \"95\": 0.17833333333333334\n",
      "  },\n",
      "  \"predicted_SoH_percent\": 9034.75,\n",
      "  \"SoH_std_estimate\": 724.4900289733498,\n",
      "  \"parsed_metadata\": {}\n",
      "}\n",
      "\n",
      "Artefacts written to models_eis_phase2_phys\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Unified EIS → SoC (classification) & SoH (regression) Model – Realistic v9‑fixed\n",
    "================================================================================\n",
    "\n",
    "• Random‑Forest classifier for SoC\n",
    "• Gaussian‑Process regressor for SoH\n",
    "• Optional capacity-test refinement & CPP‑based RUL\n",
    "• End‑to‑end artefacts written to models_eis_phase2_phys/\n",
    "\"\"\"\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "# 0. Imports\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "from __future__ import annotations\n",
    "import re, json, math, random, warnings, joblib\n",
    "from dataclasses import dataclass, asdict, field\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.io import loadmat\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    mean_squared_error, r2_score\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "# 1. Configuration\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "@dataclass\n",
    "class Config:\n",
    "    # ---------------------------------------------------------------------\n",
    "    # paths\n",
    "    EIS_DIR: Path = Path(r\"C:\\Users\\tmgon\\OneDrive - Edith Cowan University\\00 - Megallan Power\\NMC Batteries Warwick Station\\NMC\\DIB_Data\\.matfiles\\EIS_Test\")\n",
    "    CAP_DIR: Path = Path(r\"C:\\Users\\tmgon\\OneDrive - Edith Cowan University\\00 - Megallan Power\\NMC Batteries Warwick Station\\NMC\\DIB_Data\\.matfiles\\Capacity_Check\")\n",
    "    MODEL_DIR: Path = Path(\"models_eis_phase2_phys\")\n",
    "\n",
    "    # evaluate exactly these files after training\n",
    "    EIS_TEST_FILES: List[Path] = field(default_factory=lambda: [Path(\"Mazda-Battery-Cell1.xlsx\")])\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # frequency grid\n",
    "    F_MIN: float = 1e-2\n",
    "    F_MAX: float = 1e4\n",
    "    N_FREQ: int  = 60\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # train / test split\n",
    "    TEST_FRAC: float = 0.2           # by CellID\n",
    "    RANDOM_STATE: int = 42\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # dimensionality options\n",
    "    USE_PCA_SOC: bool = True\n",
    "    PCA_SOC_COMPONENTS: int = 25\n",
    "    USE_PCA_SOH: bool = False\n",
    "    PCA_SOH_COMPONENTS: int = 30\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # feature‑toggles  (only BASIC & RAW in this minimal script)\n",
    "    INCLUDE_RAW_RE_IM:  bool = True\n",
    "    INCLUDE_BASICS:     bool = True\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # DRT (disabled in this trimmed version – set True & add code if needed)\n",
    "    INCLUDE_DRT: bool = False\n",
    "    DRT_POINTS: int   = 60\n",
    "    DRT_TAU_MIN: float = 1e-4\n",
    "    DRT_TAU_MAX: float = 1e4\n",
    "    DRT_LAMBDA:  float = 1e-2\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # capacity / RUL\n",
    "    REFINE_SOH_WITH_CAPACITY: bool = True\n",
    "    CPP_ROLLING_WINDOW: int = 5\n",
    "    CPP_MIN_POINTS:    int = 6\n",
    "    CPP_FALLBACK:      float = 20.0      # cycles‑per‑percent if no cap‑data\n",
    "    DECISION_SOH_PERCENT: float = 50.0\n",
    "    ILLUSTRATIVE_MIN_SOH: float = 40.0\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # misc\n",
    "    TEST_TEMPERATURE_OVERRIDE: Optional[float] = 25.0\n",
    "    MAX_GPR_TRAIN_SAMPLES: int = 3500\n",
    "    FORCE_RETRAIN: bool = True\n",
    "    VERBOSE: bool = True\n",
    "    FEATURE_VERSION: int = 8\n",
    "\n",
    "cfg = Config()\n",
    "cfg.MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "random.seed(cfg.RANDOM_STATE)\n",
    "np.random.seed(cfg.RANDOM_STATE)\n",
    "\n",
    "CANON_FREQ = np.geomspace(cfg.F_MAX, cfg.F_MIN, cfg.N_FREQ)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "# 2. Regex helpers\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "EIS_META_PATTERN = re.compile(\n",
    "    r\"Cell(?P<CellID>\\d+)_(?P<SOH>80|85|90|95|100)SOH_\"\n",
    "    r\"(?P<Temp>\\d+)degC_(?P<SOC>\\d+)SOC_(?P<RealSOH>\\d+)\"\n",
    ")\n",
    "CAP_META_PATTERN = re.compile(\n",
    "    r\"Cell(?P<CellID>\\d+)_(?P<SOH>80|85|90|95|100)SOH_\"\n",
    "    r\"Capacity_Check_(?P<Temp>\\d+)degC_(?P<Cycle>\\d+)cycle\"\n",
    ")\n",
    "\n",
    "def parse_eis_metadata(stem: str) -> Optional[Dict[str,Any]]:\n",
    "    m = EIS_META_PATTERN.search(stem)\n",
    "    if not m: return None\n",
    "    d = m.groupdict()\n",
    "    return {\"CellID\": f\"Cell{d['CellID']}\",\n",
    "            \"SOH_stage\": int(d[\"SOH\"]),\n",
    "            \"SOC\": int(d[\"SOC\"]),\n",
    "            \"Temp\": int(d[\"Temp\"]),\n",
    "            \"RealSOH_file\": int(d[\"RealSOH\"]) / 100.0}\n",
    "\n",
    "def parse_cap_metadata(stem: str) -> Optional[Dict[str,Any]]:\n",
    "    m = CAP_META_PATTERN.search(stem)\n",
    "    if not m: return None\n",
    "    d = m.groupdict()\n",
    "    return {\"CellID\": f\"Cell{d['CellID']}\",\n",
    "            \"SOH_stage\": int(d[\"SOH\"]),\n",
    "            \"Temp\": int(d[\"Temp\"]),\n",
    "            \"CycleIndex\": int(d[\"Cycle\"])}\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "# 3. Loading helpers\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "def _find_matrix(mat_dict: dict):\n",
    "    for v in mat_dict.values():\n",
    "        if isinstance(v, np.ndarray) and v.ndim == 2 and v.shape[1] >= 3:\n",
    "            return v\n",
    "    return None\n",
    "\n",
    "def _interp_channel(freq_raw, y_raw, freq_target):\n",
    "    freq_raw = np.asarray(freq_raw, float)\n",
    "    y_raw    = np.asarray(y_raw,   float)\n",
    "    if freq_raw[0] < freq_raw[-1]:           # ensure descending\n",
    "        freq_raw = freq_raw[::-1]\n",
    "        y_raw    = y_raw[::-1]\n",
    "    uniq, idx = np.unique(freq_raw, return_index=True)\n",
    "    if len(uniq) != len(freq_raw):           # drop dups\n",
    "        order   = np.argsort(idx)\n",
    "        freq_raw, y_raw = uniq[order], y_raw[idx][order]\n",
    "    f = interp1d(freq_raw, y_raw, bounds_error=False,\n",
    "                 fill_value=(y_raw[0], y_raw[-1]), kind=\"linear\")\n",
    "    return f(freq_target)\n",
    "\n",
    "FREQ_CANDS = [\"frequency\",\"freq\",\"f\",\"hz\",\"Frequency(Hz)\"]\n",
    "RE_CANDS   = [\"zreal\",\"re\",\"real\",\"Zreal\",\"Zreal (ohm)\"]\n",
    "IM_CANDS   = [\"-zimag\",\"zimag\",\"im\",\"imag\",\"Zimag\",\"Zimag (ohm)\"]\n",
    "\n",
    "def _sel_col(df, cands):\n",
    "    lower={c.lower():c for c in df.columns}\n",
    "    for c in cands:\n",
    "        if c.lower() in lower: return lower[c.lower()]\n",
    "    for c in cands:\n",
    "        for col in df.columns:\n",
    "            if c.lower() in col.lower(): return col\n",
    "    return None\n",
    "\n",
    "def load_mat_eis(path: Path):\n",
    "    arr=_find_matrix(loadmat(path))\n",
    "    if arr is None: raise ValueError(\"no valid matrix\")\n",
    "    return arr[:,0], arr[:,1], arr[:,2]\n",
    "\n",
    "def load_table_eis(path: Path):\n",
    "    df = pd.read_csv(path) if path.suffix.lower()==\".csv\" else pd.read_excel(path)\n",
    "\n",
    "    fcol = _sel_col(df, FREQ_CANDS)\n",
    "    rcol = _sel_col(df, RE_CANDS)\n",
    "    icol = _sel_col(df, IM_CANDS)\n",
    "    if rcol is None or icol is None:\n",
    "        raise ValueError(f\"Missing Re/Im columns in {path.name}\")\n",
    "\n",
    "    re   = pd.to_numeric(df[rcol], errors=\"coerce\").values\n",
    "    im   = pd.to_numeric(df[icol], errors=\"coerce\").values\n",
    "    if fcol:\n",
    "        freq = pd.to_numeric(df[fcol], errors=\"coerce\").values\n",
    "    else:\n",
    "        freq = np.geomspace(cfg.F_MAX, cfg.F_MIN, len(re))\n",
    "\n",
    "    if np.nanmean(im) > 0:                        # enforce capacitive sign\n",
    "        im = -im\n",
    "    n = min(len(freq), len(re), len(im))\n",
    "    return freq[:n], re[:n], im[:n]\n",
    "\n",
    "def load_any(path: Path):\n",
    "    suf = path.suffix.lower()\n",
    "    if suf == \".mat\":  return load_mat_eis(path)\n",
    "    if suf in (\".csv\",\".xls\",\".xlsx\"): return load_table_eis(path)\n",
    "    raise ValueError(f\"unsupported file type {suf}\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "# 4. Features   (RAW + BASIC only for brevity)\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "def basic_feats(re_i, im_i):\n",
    "    z = np.hypot(re_i, im_i)\n",
    "    return [re_i[0], re_i[-1], re_i[-1]-re_i[0], z.max(), z.mean(), z.std()]\n",
    "\n",
    "def build_feature_vector(re_i, im_i, temp, freq):\n",
    "    parts=[]\n",
    "    if cfg.INCLUDE_RAW_RE_IM:\n",
    "        parts += [re_i, im_i]\n",
    "    if cfg.INCLUDE_BASICS:\n",
    "        parts.append(basic_feats(re_i, im_i))\n",
    "    parts.append([temp])\n",
    "    v = np.concatenate(parts).astype(float)\n",
    "    return np.nan_to_num(v, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "# 5. Capacity helpers (CPP / label refinement)\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "def load_capacity_df(cap_dir: Path):\n",
    "    if not cap_dir.exists(): return pd.DataFrame()\n",
    "    recs=[]\n",
    "    for fp in cap_dir.rglob(\"*.mat\"):\n",
    "        meta = parse_cap_metadata(fp.stem)\n",
    "        if not meta: continue\n",
    "        try:\n",
    "            arr = _find_matrix(loadmat(fp))\n",
    "            col = np.argmax(np.abs(arr[-50:,:]).mean(axis=0))\n",
    "            meta[\"MeasuredCapacity_Ah\"] = float(np.nanmax(arr[:,col]))\n",
    "            recs.append(meta)\n",
    "        except Exception:\n",
    "            pass\n",
    "    df = pd.DataFrame(recs)\n",
    "    if df.empty: return df\n",
    "    ref=df.groupby(\"CellID\")[\"MeasuredCapacity_Ah\"].transform(\"max\")\n",
    "    df[\"NormCapacity\"]=df[\"MeasuredCapacity_Ah\"]/ref\n",
    "    df[\"SoH_percent\"]=df[\"NormCapacity\"]*100.0\n",
    "    return df\n",
    "\n",
    "def estimate_cpp(cap_df: pd.DataFrame):\n",
    "    cpp={}\n",
    "    for cid, grp in cap_df.groupby(\"CellID\"):\n",
    "        if grp.shape[0] < cfg.CPP_MIN_POINTS: continue\n",
    "        tail = grp.sort_values(\"CycleIndex\").tail(cfg.CPP_ROLLING_WINDOW)\n",
    "        x, y = tail.CycleIndex.values, tail.SoH_percent.values\n",
    "        if len(np.unique(x)) < 2: continue\n",
    "        slope = np.polyfit(x, y, 1)[0]\n",
    "        if slope < -1e-6:\n",
    "            cpp[cid] = 1.0/abs(slope)\n",
    "    return cpp\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "# 6. Build dataset\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "def load_single_mat(fp: Path):\n",
    "    meta=parse_eis_metadata(fp.stem)\n",
    "    freq,re_raw,im_raw = load_mat_eis(fp)\n",
    "    re_i=_interp_channel(freq,re_raw,CANON_FREQ)\n",
    "    im_i=_interp_channel(freq,im_raw,CANON_FREQ)\n",
    "    return meta, re_i, im_i\n",
    "\n",
    "def build_dataset(eis_dir: Path, cap_df: pd.DataFrame):\n",
    "    files = sorted(eis_dir.rglob(\"*.mat\"))\n",
    "    if not files: raise FileNotFoundError(\"No .mat spectra found\")\n",
    "\n",
    "    rows, feats = [], []\n",
    "    for fp in tqdm(files, desc=\"Load spectra\"):\n",
    "        try:\n",
    "            meta, re_i, im_i = load_single_mat(fp)\n",
    "            vec = build_feature_vector(re_i, im_i, meta[\"Temp\"], CANON_FREQ)\n",
    "            rows.append(meta); feats.append(vec)\n",
    "        except Exception as e:\n",
    "            if cfg.VERBOSE: print(f\"[skip] {fp.name}: {e}\")\n",
    "\n",
    "    meta_df = pd.DataFrame(rows)\n",
    "    X_raw   = np.vstack(feats)\n",
    "\n",
    "    # --- refine SoH labels with capacity tests ---------------------------\n",
    "    if cfg.REFINE_SOH_WITH_CAPACITY and not cap_df.empty:\n",
    "        lk = cap_df.set_index([\"CellID\",\"SOH_stage\"])[\"NormCapacity\"].to_dict()\n",
    "        refined=[]\n",
    "        for cid, stage, fallback in zip(meta_df.CellID, meta_df.SOH_stage, meta_df.RealSOH_file):\n",
    "            v = lk.get((cid, stage))\n",
    "            refined.append(100.0*v if v is not None else fallback*100.0)\n",
    "        meta_df[\"SoH_cont\"] = refined\n",
    "    else:\n",
    "        meta_df[\"SoH_cont\"] = meta_df[\"RealSOH_file\"]*100\n",
    "\n",
    "    return meta_df, X_raw, meta_df.SOC.values, meta_df.SoH_cont.values\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "# 7. Train & plot\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "def split_mask(df):\n",
    "    cells = df.CellID.unique()\n",
    "    rng   = np.random.default_rng(cfg.RANDOM_STATE)\n",
    "    test  = rng.choice(cells, size=max(1,int(len(cells)*cfg.TEST_FRAC)), replace=False)\n",
    "    return df.CellID.isin(test)\n",
    "\n",
    "def train_models(meta_df, X_raw, y_soc, y_soh):\n",
    "    mtest = split_mask(meta_df)\n",
    "\n",
    "    # --- SoC --------------------------------------------------------------\n",
    "    soc_scaler = StandardScaler().fit(X_raw)\n",
    "    X_soc_s    = soc_scaler.transform(X_raw)\n",
    "    soc_pca    = PCA(n_components=min(cfg.PCA_SOC_COMPONENTS,X_soc_s.shape[1]-1),\n",
    "                     random_state=cfg.RANDOM_STATE).fit(X_soc_s) if cfg.USE_PCA_SOC else None\n",
    "    X_soc_in   = soc_pca.transform(X_soc_s) if soc_pca else X_soc_s\n",
    "    soc_model  = RandomForestClassifier(n_estimators=600,class_weight=\"balanced\",\n",
    "                                        random_state=cfg.RANDOM_STATE).fit(\n",
    "                     X_soc_in[~mtest], y_soc[~mtest])\n",
    "\n",
    "    y_pred = soc_model.predict(X_soc_in[mtest])\n",
    "    cm     = confusion_matrix(y_soc[mtest], y_pred, labels=soc_model.classes_)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(cm, cmap=\"Blues\")\n",
    "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "    plt.xticks(range(len(soc_model.classes_)), soc_model.classes_)\n",
    "    plt.yticks(range(len(soc_model.classes_)), soc_model.classes_)\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j,i,cm[i,j],ha=\"center\",va=\"center\")\n",
    "    plt.tight_layout(); plt.savefig(cfg.MODEL_DIR/\"soc_confusion.png\", dpi=150); plt.close()\n",
    "\n",
    "    if cfg.VERBOSE:\n",
    "        print(\"\\n[SoC] accuracy:\",\n",
    "              accuracy_score(y_soc[mtest], y_pred))\n",
    "        print(classification_report(y_soc[mtest], y_pred, digits=4))\n",
    "\n",
    "    # --- SoH --------------------------------------------------------------\n",
    "    soh_scaler = StandardScaler().fit(X_raw)\n",
    "    X_soh_s    = soh_scaler.transform(X_raw)\n",
    "    soh_pca    = PCA(n_components=min(cfg.PCA_SOH_COMPONENTS,X_soh_s.shape[1]-1),\n",
    "                     random_state=cfg.RANDOM_STATE).fit(X_soh_s) if cfg.USE_PCA_SOH else None\n",
    "    X_soh_in   = soh_pca.transform(X_soh_s) if soh_pca else X_soh_s\n",
    "\n",
    "    kernel = RBF(length_scale=np.ones(X_soh_in.shape[1])*3.0,\n",
    "                 length_scale_bounds=(1e-1,1e4)) + WhiteKernel(1e-2,(1e-6,1e-1))\n",
    "    gpr = GaussianProcessRegressor(kernel=kernel, normalize_y=True,\n",
    "                                   n_restarts_optimizer=3, random_state=cfg.RANDOM_STATE)\n",
    "    if X_soh_in.shape[0] > cfg.MAX_GPR_TRAIN_SAMPLES:\n",
    "        idx = np.random.default_rng(cfg.RANDOM_STATE)\\\n",
    "                 .choice(X_soh_in.shape[0], size=cfg.MAX_GPR_TRAIN_SAMPLES, replace=False)\n",
    "        gpr.fit(X_soh_in[idx], y_soh[idx])\n",
    "    else:\n",
    "        gpr.fit(X_soh_in, y_soh)\n",
    "\n",
    "    # quick scatter plot\n",
    "    y_pred_test = gpr.predict(X_soh_in[mtest])\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.scatter(y_soh[mtest], y_pred_test, s=18)\n",
    "    lo,hi=min(y_soh[mtest].min(),y_pred_test.min()), max(y_soh[mtest].max(),y_pred_test.max())\n",
    "    plt.plot([lo,hi],[lo,hi],'k--',lw=1)\n",
    "    plt.xlabel(\"True SoH\"); plt.ylabel(\"Pred\"); plt.tight_layout()\n",
    "    plt.savefig(cfg.MODEL_DIR/\"soh_regression_test.png\", dpi=150); plt.close()\n",
    "\n",
    "    print(f\"[SoH] R² test = {r2_score(y_soh[mtest], y_pred_test):.3f}\")\n",
    "\n",
    "    return {\"soc_scaler\":soc_scaler, \"soc_pca\":soc_pca, \"soc_model\":soc_model,\n",
    "            \"soh_scaler\":soh_scaler, \"soh_pca\":soh_pca, \"soh_model\":gpr,\n",
    "            \"freq_grid\":CANON_FREQ}\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "# 8. Inference helpers\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "def featurize(path: Path, bundle):\n",
    "    meta = parse_eis_metadata(path.stem) or {}\n",
    "    f,re,im = load_any(path)\n",
    "    re_i = _interp_channel(f,re,bundle[\"freq_grid\"])\n",
    "    im_i = _interp_channel(f,im,bundle[\"freq_grid\"])\n",
    "    temp = meta.get(\"Temp\", cfg.TEST_TEMPERATURE_OVERRIDE or -1)\n",
    "    return build_feature_vector(re_i, im_i, temp, bundle[\"freq_grid\"]), meta\n",
    "\n",
    "def predict(path: Path, bundle):\n",
    "    v, meta = featurize(path, bundle)\n",
    "\n",
    "    # SoC\n",
    "    x = bundle[\"soc_scaler\"].transform(v.reshape(1,-1))\n",
    "    if bundle[\"soc_pca\"] is not None:\n",
    "        x = bundle[\"soc_pca\"].transform(x)\n",
    "    soc_pred = int(bundle[\"soc_model\"].predict(x)[0])\n",
    "    soc_prob = bundle[\"soc_model\"].predict_proba(x)[0]\n",
    "\n",
    "    # SoH\n",
    "    xs = bundle[\"soh_scaler\"].transform(v.reshape(1,-1))\n",
    "    if bundle[\"soh_pca\"] is not None:\n",
    "        xs = bundle[\"soh_pca\"].transform(xs)\n",
    "    soh_mean, soh_std = bundle[\"soh_model\"].predict(xs, return_std=True)\n",
    "    return {\"file\": str(path),\n",
    "            \"predicted_SoC\": soc_pred,\n",
    "            \"SoC_probabilities\": {int(c):float(p) for c,p in zip(bundle[\"soc_model\"].classes_, soc_prob)},\n",
    "            \"predicted_SoH_percent\": float(soh_mean[0]),\n",
    "            \"SoH_std_estimate\": float(soh_std[0]),\n",
    "            \"parsed_metadata\": meta}\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "# 9. RUL projection (optional, uses CPP map)\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "def build_projection(soh,cpp,lower,exp=1.25,n=150):\n",
    "    if soh<=lower or cpp<=0: return np.array([0]), np.array([soh])\n",
    "    total=(soh-lower)*cpp\n",
    "    cycles=np.linspace(0,total,n)\n",
    "    curve=lower+(soh-lower)*(1-cycles/total)**exp\n",
    "    return cycles,curve\n",
    "\n",
    "def plot_projection(base,soh,std,cpp,out):\n",
    "    cyc,cur=build_projection(soh,cpp,cfg.ILLUSTRATIVE_MIN_SOH)\n",
    "    plt.figure(figsize=(5.5,4))\n",
    "    plt.plot(cyc,cur,lw=2); plt.axhline(cfg.DECISION_SOH_PERCENT,ls=\"--\",color=\"orange\")\n",
    "    plt.axhline(cfg.ILLUSTRATIVE_MIN_SOH,ls=\":\",color=\"red\")\n",
    "    plt.scatter([0],[soh],c=\"green\"); plt.text(0,soh+0.5,f\"{soh:.1f}±{std:.1f}%\")\n",
    "    plt.xlabel(\"Remaining cycles\"); plt.ylabel(\"SoH (%)\")\n",
    "    plt.title(f\"RUL projection – {base}\"); plt.tight_layout()\n",
    "    plt.savefig(out,dpi=140); plt.close()\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "# 10. Main\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "def main():\n",
    "    # --- capacity data (optional) ----------------------------------------\n",
    "    cap_df = load_capacity_df(cfg.CAP_DIR) if cfg.REFINE_SOH_WITH_CAPACITY else pd.DataFrame()\n",
    "    cpp_map = estimate_cpp(cap_df) if not cap_df.empty else {}\n",
    "    global_cpp = np.median(list(cpp_map.values())) if cpp_map else cfg.CPP_FALLBACK\n",
    "\n",
    "    # --- dataset + training ----------------------------------------------\n",
    "    meta_df,X,y_soc,y_soh = build_dataset(cfg.EIS_DIR, cap_df)\n",
    "    bundle = train_models(meta_df,X,y_soc,y_soh)\n",
    "    joblib.dump(bundle, cfg.MODEL_DIR/\"eis_soc_soh_phys_models.joblib\")\n",
    "\n",
    "    # --- inference on each test file -------------------------------------\n",
    "    for tf in cfg.EIS_TEST_FILES:\n",
    "        if not tf.exists():\n",
    "            print(f\"[WARN] {tf} not found\"); continue\n",
    "        res = predict(tf,bundle)\n",
    "        print(\"\\n\",json.dumps(res, indent=2))\n",
    "\n",
    "        cpp = cpp_map.get(res[\"parsed_metadata\"].get(\"CellID\"), global_cpp)\n",
    "        plot_projection(tf.stem, res[\"predicted_SoH_percent\"],\n",
    "                        res[\"SoH_std_estimate\"], cpp,\n",
    "                        cfg.MODEL_DIR/f\"{tf.stem}_projection.png\")\n",
    "\n",
    "        with open(cfg.MODEL_DIR/f\"{tf.stem}_prediction.json\",\"w\") as f:\n",
    "            json.dump(res,f,indent=2)\n",
    "\n",
    "    print(\"\\nArtefacts written to\", cfg.MODEL_DIR)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e67101-a634-40f8-aa18-09ec268296ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
