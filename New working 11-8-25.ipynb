{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6633bc1-395e-4bf2-9e23-0e1ed53c6a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      " {\n",
      "  \"EIS_DIR\": \"C:\\\\Users\\\\tgondal0\\\\OneDrive - Edith Cowan University\\\\00 - Megallan Power\\\\NMC Batteries Warwick Station\\\\NMC\\\\DIB_Data\\\\.matfiles\\\\EIS_Test\",\n",
      "  \"CAP_DIR\": \"C:\\\\Users\\\\tgondal0\\\\OneDrive - Edith Cowan University\\\\00 - Megallan Power\\\\NMC Batteries Warwick Station\\\\NMC\\\\DIB_Data\\\\.matfiles\\\\Capacity_Check\",\n",
      "  \"MODEL_DIR\": \"models_eis_phase2_phys\",\n",
      "  \"EIS_TEST_FILES\": [\n",
      "    \"Mazda-Battery-Cell1.xlsx\"\n",
      "  ],\n",
      "  \"F_MIN\": 0.01,\n",
      "  \"F_MAX\": 10000.0,\n",
      "  \"N_FREQ\": 60,\n",
      "  \"TEST_FRAC\": 0.2,\n",
      "  \"GROUP_KFOLDS\": 0,\n",
      "  \"RANDOM_STATE\": 42,\n",
      "  \"USE_PCA_SOC\": true,\n",
      "  \"USE_PCA_SOH\": false,\n",
      "  \"PCA_SOC_COMPONENTS\": 25,\n",
      "  \"PCA_SOH_COMPONENTS\": 30,\n",
      "  \"INCLUDE_RAW_RE_IM\": true,\n",
      "  \"INCLUDE_BASICS\": true,\n",
      "  \"INCLUDE_F_FEATS\": true,\n",
      "  \"INCLUDE_PHYSICAL\": true,\n",
      "  \"INCLUDE_DRT\": true,\n",
      "  \"INCLUDE_BAND_STATS\": true,\n",
      "  \"INCLUDE_DIFF_SLOPES\": true,\n",
      "  \"DRT_POINTS\": 60,\n",
      "  \"DRT_TAU_MIN\": 0.0001,\n",
      "  \"DRT_TAU_MAX\": 10000.0,\n",
      "  \"DRT_LAMBDA\": 0.01,\n",
      "  \"REFINE_SOH_WITH_CAPACITY\": true,\n",
      "  \"MAX_GPR_TRAIN_SAMPLES\": 3500,\n",
      "  \"INCLUDE_NORMALIZED_SHAPE_MODEL\": true,\n",
      "  \"ENSEMBLE_SOH\": true,\n",
      "  \"NORMALIZE_SHAPE_BY_HF_RE\": true,\n",
      "  \"SOC_INCLUDE_SHAPE_MODEL\": true,\n",
      "  \"SOC_MAX_GPR_TRAIN_SAMPLES\": 3500,\n",
      "  \"DECISION_SOH_PERCENT\": 50.0,\n",
      "  \"ILLUSTRATIVE_MIN_SOH\": 40.0,\n",
      "  \"CPP_ROLLING_WINDOW\": 5,\n",
      "  \"CPP_MIN_POINTS\": 6,\n",
      "  \"CPP_FALLBACK\": 20.0,\n",
      "  \"TEST_TEMPERATURE_OVERRIDE\": 25.0,\n",
      "  \"FORCE_RETRAIN\": false,\n",
      "  \"SAVE_FEATURE_TABLE\": true,\n",
      "  \"VERBOSE\": true,\n",
      "  \"FEATURE_VERSION\": 8,\n",
      "  \"MAHAL_THRESHOLD\": 10.0,\n",
      "  \"GP_ARD_NORM_THRESHOLD\": 6.0,\n",
      "  \"PLOT_EXPONENT\": 1.25\n",
      "}\n",
      "[INFO] No / empty capacity data -> fallback Cpp.\n",
      "[TRAIN] Building dataset & training models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading training spectra: 100%|██████████| 360/360 [00:01<00:00, 227.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DATA] SoH range: 80.46 – 100.00 (var=52.028)\n",
      "[TRAIN] Samples=360 Features=173 Cells=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 6 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 15 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 14 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 21 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoC] GPR_raw:   R2=0.977 RMSE=4.91\n",
      "[SoC] HGB_raw:   R2=0.819 RMSE=13.90\n",
      "[SoC] ShapeGP:  R2=0.979 RMSE=4.78\n",
      "[SoC] Selected = soc_gpr_shape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 9 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 48 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 60 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 61 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 62 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 63 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 64 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 65 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 66 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 67 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 68 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 69 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 70 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 71 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 100 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 101 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 120 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 126 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 133 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 140 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 143 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 144 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 157 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 162 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 164 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 166 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 169 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 1 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 2 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 3 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 4 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 5 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 6 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 7 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 8 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 9 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 10 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 11 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 14 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 16 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 22 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 23 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 24 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 25 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 31 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 60 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 61 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 62 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 63 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 64 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 65 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 66 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 67 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 68 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 69 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 70 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 71 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 75 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 76 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 77 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 78 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 79 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 80 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 81 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 84 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 91 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 129 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 136 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 137 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 140 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 143 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 144 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 155 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 162 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 164 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 169 of parameter k1__length_scale is close to the specified upper bound 10000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tgondal0\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:442: ConvergenceWarning: The optimal value found for dimension 172 of parameter k1__length_scale is close to the specified lower bound 0.1. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoH] GPR_raw:  R2=0.995 RMSE=0.37\n",
      "[SoH] HGB_raw:  R2=0.571 RMSE=3.61\n",
      "[SoH] ShapeGP: R2=0.994 RMSE=0.43\n",
      "[SoH] Selected raw model = gpr_raw\n",
      "[MODEL] Saved bundle → models_eis_phase2_phys\\eis_soc_soh_phys_models.joblib\n",
      "{\n",
      "  \"soc_r2_selected\": 0.978540857869718,\n",
      "  \"soc_rmse_selected\": 4.78282819165404,\n",
      "  \"soh_r2_selected\": 0.9953987333752046,\n",
      "  \"soh_rmse_selected\": 0.37392841054767223\n",
      "}\n",
      "\n",
      "===== TEST: Mazda-Battery-Cell1.xlsx =====\n",
      "{\n",
      "  \"file\": \"Mazda-Battery-Cell1.xlsx\",\n",
      "  \"parsed_metadata\": null,\n",
      "  \"predicted_SoC_percent\": 48.0,\n",
      "  \"SoC_std_estimate\": 33.12242526854917,\n",
      "  \"soc_model_chosen\": \"soc_gpr_shape\",\n",
      "  \"SoC_probabilities\": null,\n",
      "  \"predicted_SoH_percent\": 90.3475,\n",
      "  \"SoH_std_estimate\": 7.241065855707704,\n",
      "  \"raw_model_mean\": 90.3475,\n",
      "  \"raw_model_std\": 7.241980250868564,\n",
      "  \"shape_model_mean\": 90.3475,\n",
      "  \"shape_model_std\": 7.240151345063277,\n",
      "  \"cycles_per_percent_used\": 20.0,\n",
      "  \"cycles_to_target\": 806.9499999999999,\n",
      "  \"cycles_to_lower\": 1006.9499999999999,\n",
      "  \"decision_threshold_percent\": 50.0,\n",
      "  \"lower_threshold_percent\": 40.0,\n",
      "  \"feature_version\": 8,\n",
      "  \"soh_model_chosen\": \"gpr_raw\",\n",
      "  \"OOD_mahal\": 2590.3953365386797,\n",
      "  \"OOD_gp_ard_norm\": 20.50488563985117,\n",
      "  \"OOD_flag\": true\n",
      "}\n",
      "[PLOT] Saved: models_eis_phase2_phys\\Mazda-Battery-Cell1_projection.png\n",
      "[JSON] Saved: models_eis_phase2_phys\\Mazda-Battery-Cell1_prediction.json\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Optimized Unified EIS Training + Inference + Dynamic RUL (v8 – SoC Regression)\n",
    "-------------------------------------------------------------------------------\n",
    "What's new vs v7:\n",
    "  • SoC is now a regression task (not classification). We train both:\n",
    "      - Gaussian Process Regressor (with uncertainty)\n",
    "      - HistGradientBoostingRegressor\n",
    "    and auto-select the best by validation R² (optionally also a shape-normalized GP).\n",
    "  • Backward-compat loader still supports legacy bundles with a classifier SoC model.\n",
    "    Inference handles both cases gracefully.\n",
    "  • JSON now includes:\n",
    "      - predicted_SoC_percent (float), SoC_std_estimate, soc_model_chosen\n",
    "      - SoC_probabilities only if a legacy classifier is used\n",
    "\n",
    "All other features remain: rich EIS features, DRT descriptors, SoH ensemble, dynamic CPP, OOD checks, plots.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import re, json, math, random, warnings, joblib\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.io import loadmat\n",
    "from scipy import linalg\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# 1. CONFIGURATION\n",
    "# =========================\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Training data directories (update if needed)\n",
    "    EIS_DIR: Path = Path(r\"C:\\Users\\tgondal0\\OneDrive - Edith Cowan University\\00 - Megallan Power\\NMC Batteries Warwick Station\\NMC\\DIB_Data\\.matfiles\\EIS_Test\")\n",
    "    CAP_DIR: Path = Path(r\"C:\\Users\\tgondal0\\OneDrive - Edith Cowan University\\00 - Megallan Power\\NMC Batteries Warwick Station\\NMC\\DIB_Data\\.matfiles\\Capacity_Check\")\n",
    "    MODEL_DIR: Path = Path(\"models_eis_phase2_phys\")\n",
    "\n",
    "    # Test files (multi-format allowed)\n",
    "    EIS_TEST_FILES: List[Path] = None  # assigned after instantiation\n",
    "\n",
    "    # Frequency interpolation grid\n",
    "    F_MIN: float = 1e-2\n",
    "    F_MAX: float = 1e4\n",
    "    N_FREQ: int = 60\n",
    "\n",
    "    # Train / split settings\n",
    "    TEST_FRAC: float = 0.2        # fraction of cells for hold-out test\n",
    "    GROUP_KFOLDS: int = 0         # (reserved)\n",
    "    RANDOM_STATE: int = 42\n",
    "\n",
    "    # PCA toggles (separate for SoC & SoH)\n",
    "    USE_PCA_SOC: bool = True\n",
    "    USE_PCA_SOH: bool = False\n",
    "    PCA_SOC_COMPONENTS: int = 25\n",
    "    PCA_SOH_COMPONENTS: int = 30\n",
    "\n",
    "    # Feature group toggles\n",
    "    INCLUDE_RAW_RE_IM: bool = True\n",
    "    INCLUDE_BASICS: bool = True\n",
    "    INCLUDE_F_FEATS: bool = True\n",
    "    INCLUDE_PHYSICAL: bool = True\n",
    "    INCLUDE_DRT: bool = True\n",
    "    INCLUDE_BAND_STATS: bool = True\n",
    "    INCLUDE_DIFF_SLOPES: bool = True\n",
    "\n",
    "    # DRT params\n",
    "    DRT_POINTS: int = 60\n",
    "    DRT_TAU_MIN: float = 1e-4\n",
    "    DRT_TAU_MAX: float = 1e4\n",
    "    DRT_LAMBDA: float = 1e-2\n",
    "\n",
    "    # Capacity-based refinement\n",
    "    REFINE_SOH_WITH_CAPACITY: bool = True\n",
    "\n",
    "    # SoH modeling\n",
    "    MAX_GPR_TRAIN_SAMPLES: int = 3500\n",
    "    INCLUDE_NORMALIZED_SHAPE_MODEL: bool = True\n",
    "    ENSEMBLE_SOH: bool = True\n",
    "    NORMALIZE_SHAPE_BY_HF_RE: bool = True\n",
    "\n",
    "    # NEW: SoC modeling\n",
    "    SOC_INCLUDE_SHAPE_MODEL: bool = True\n",
    "    SOC_MAX_GPR_TRAIN_SAMPLES: int = 3500\n",
    "\n",
    "    # RUL parameters\n",
    "    DECISION_SOH_PERCENT: float = 50.0\n",
    "    ILLUSTRATIVE_MIN_SOH: float = 40.0\n",
    "    CPP_ROLLING_WINDOW: int = 5\n",
    "    CPP_MIN_POINTS: int = 6\n",
    "    CPP_FALLBACK: float = 20.0  # fallback cycles-per-percent\n",
    "\n",
    "    # Inference extras\n",
    "    TEST_TEMPERATURE_OVERRIDE: Optional[float] = 25.0  # applied if metadata absent\n",
    "    FORCE_RETRAIN: bool = False  # force retraining even if bundle exists\n",
    "\n",
    "    # Saving / logging\n",
    "    SAVE_FEATURE_TABLE: bool = True\n",
    "    VERBOSE: bool = True\n",
    "    FEATURE_VERSION: int = 8\n",
    "\n",
    "    # OOD thresholds\n",
    "    MAHAL_THRESHOLD: float = 10.0\n",
    "    GP_ARD_NORM_THRESHOLD: float = 6.0\n",
    "\n",
    "    # Projection curve shape exponent\n",
    "    PLOT_EXPONENT: float = 1.25\n",
    "\n",
    "cfg = Config()\n",
    "if cfg.EIS_TEST_FILES is None:\n",
    "    cfg.EIS_TEST_FILES = [\n",
    "        Path(\"Mazda-Battery-Cell1.xlsx\")\n",
    "    ]\n",
    "cfg.MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# 2. UTILITIES\n",
    "# =========================\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "set_seed(cfg.RANDOM_STATE)\n",
    "\n",
    "def to_jsonable(x):\n",
    "    if isinstance(x, Path): return str(x)\n",
    "    if isinstance(x, dict): return {k: to_jsonable(v) for k,v in x.items()}\n",
    "    if isinstance(x, (list, tuple)): return [to_jsonable(i) for i in x]\n",
    "    return x\n",
    "\n",
    "CANON_FREQ = np.geomspace(cfg.F_MAX, cfg.F_MIN, cfg.N_FREQ)\n",
    "\n",
    "# =========================\n",
    "# 3. REGEX\n",
    "# =========================\n",
    "EIS_META_PATTERN = re.compile(\n",
    "    r\"Cell(?P<CellID>\\d+)_(?P<SOH>80|85|90|95|100)SOH_(?P<Temp>\\d+)degC_(?P<SOC>\\d+)SOC_(?P<RealSOH>\\d+)\"\n",
    ")\n",
    "CAP_META_PATTERN = re.compile(\n",
    "    r\"Cell(?P<CellID>\\d+)_(?P<SOH>80|85|90|95|100)SOH_Capacity_Check_(?P<Temp>\\d+)degC_(?P<Cycle>\\d+)cycle\"\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 4. PARSERS\n",
    "# =========================\n",
    "def parse_eis_metadata(stem: str) -> Optional[Dict[str, Any]]:\n",
    "    m = EIS_META_PATTERN.search(stem)\n",
    "    if not m: return None\n",
    "    d = m.groupdict()\n",
    "    return {\n",
    "        \"CellID\": f\"Cell{d['CellID']}\",\n",
    "        \"SOH_stage\": int(d[\"SOH\"]),\n",
    "        \"SOC\": float(d[\"SOC\"]),           # keep as float for regression\n",
    "        \"Temp\": int(d[\"Temp\"]),\n",
    "        \"RealSOH_file\": int(d[\"RealSOH\"])/100.0\n",
    "    }\n",
    "\n",
    "def parse_cap_metadata(stem: str) -> Optional[Dict[str, Any]]:\n",
    "    m = CAP_META_PATTERN.search(stem)\n",
    "    if not m: return None\n",
    "    d = m.groupdict()\n",
    "    return {\n",
    "        \"CellID\": f\"Cell{d['CellID']}\",\n",
    "        \"SOH_stage\": int(d[\"SOH\"]),\n",
    "        \"Temp\": int(d[\"Temp\"]),\n",
    "        \"CycleIndex\": int(d[\"Cycle\"])\n",
    "    }\n",
    "\n",
    "# =========================\n",
    "# 5. LOW-LEVEL LOADERS / INTERPOLATION\n",
    "# =========================\n",
    "def _find_matrix(mat_dict: dict):\n",
    "    for v in mat_dict.values():\n",
    "        if isinstance(v, np.ndarray) and v.ndim == 2 and v.shape[1] >= 3 and v.shape[0] >= 10:\n",
    "            return v\n",
    "    return None\n",
    "\n",
    "def _interp_channel(freq_raw, y_raw, freq_target):\n",
    "    freq_raw = np.asarray(freq_raw).astype(float)\n",
    "    y_raw = np.asarray(y_raw).astype(float)\n",
    "    if freq_raw[0] < freq_raw[-1]:\n",
    "        freq_raw = freq_raw[::-1]; y_raw = y_raw[::-1]\n",
    "    uniq, idx = np.unique(freq_raw, return_index=True)\n",
    "    if len(uniq) != len(freq_raw):\n",
    "        order = np.argsort(idx)\n",
    "        freq_raw = uniq[order]; y_raw = y_raw[idx][order]\n",
    "    f = interp1d(freq_raw, y_raw, bounds_error=False,\n",
    "                 fill_value=(y_raw[0], y_raw[-1]), kind=\"linear\")\n",
    "    return f(freq_target)\n",
    "\n",
    "FREQ_CANDS = [\"frequency\",\"freq\",\"f\",\"hz\",\"frequency(hz)\",\"Frequency(Hz)\"]\n",
    "RE_CANDS   = [\"zreal\",\"re(z)\",\"re\",\"real\",\"z_re\",\"zreal(ohm)\",\"re (ohm)\",\"re(z) (ohm)\",\"Zreal\",\"Zreal (ohm)\",\"Zreal(ohm)\"]\n",
    "IM_CANDS   = [\"-zimag\",\"zimag\",\"im(z)\",\"im\",\"imag\",\"imaginary\",\"z_im\",\"zimg\",\"z_imag\",\" -Zimag (ohm)\",\" -Zimag(ohm)\",\"-Zimag\",\"Zimag\",\"Zimag (ohm)\"]\n",
    "\n",
    "def _select_column(df: pd.DataFrame, cands: List[str]) -> Optional[str]:\n",
    "    low = {c.lower(): c for c in df.columns}\n",
    "    for c in cands:\n",
    "        if c.lower() in low: return low[c.lower()]\n",
    "    for c in cands:\n",
    "        for col in df.columns:\n",
    "            if c.lower() in col.lower():\n",
    "                return col\n",
    "    return None\n",
    "\n",
    "def load_mat_eis(path: Path):\n",
    "    mat = loadmat(path)\n",
    "    arr = _find_matrix(mat)\n",
    "    if arr is None:\n",
    "        raise ValueError(f\"No valid EIS matrix in {path.name}\")\n",
    "    return arr[:,0].astype(float), arr[:,1].astype(float), arr[:,2].astype(float)\n",
    "\n",
    "def load_table_eis(path: Path):\n",
    "    if path.suffix.lower() == \".csv\":\n",
    "        df = pd.read_csv(path)\n",
    "    else:\n",
    "        df = pd.read_excel(path)\n",
    "    if df.empty:\n",
    "        raise ValueError(\"Empty table.\")\n",
    "    fcol = _select_column(df, FREQ_CANDS)\n",
    "    recol = _select_column(df, RE_CANDS)\n",
    "    imcol = _select_column(df, IM_CANDS)\n",
    "    if recol is None or imcol is None:\n",
    "        raise ValueError(f\"Missing Re/Im columns in {path.name}\")\n",
    "    re_vals = pd.to_numeric(df[recol], errors=\"coerce\").to_numpy()\n",
    "    im_vals = pd.to_numeric(df[imcol], errors=\"coerce\").to_numpy()\n",
    "    if fcol is not None:\n",
    "        freq_vals = pd.to_numeric(df[fcol], errors=\"coerce\").to_numpy()\n",
    "    else:\n",
    "        n = min(len(re_vals), len(im_vals))\n",
    "        freq_vals = np.geomspace(cfg.F_MAX, cfg.F_MIN, n)\n",
    "    n = min(len(freq_vals), len(re_vals), len(im_vals))\n",
    "    freq_vals = freq_vals[:n]; re_vals = re_vals[:n]; im_vals = im_vals[:n]\n",
    "    if np.nanmean(im_vals) > 0:\n",
    "        im_vals = -im_vals\n",
    "    return freq_vals, re_vals.astype(float), im_vals.astype(float)\n",
    "\n",
    "def load_any_inference(path: Path):\n",
    "    suf = path.suffix.lower()\n",
    "    if suf == \".mat\": return load_mat_eis(path)\n",
    "    if suf in (\".csv\",\".xls\",\".xlsx\"): return load_table_eis(path)\n",
    "    raise ValueError(f\"Unsupported test file extension: {suf}\")\n",
    "\n",
    "# =========================\n",
    "# 6. FEATURE ENGINEERING\n",
    "# =========================\n",
    "def compute_F_features(freq, re_i, im_i):\n",
    "    neg_im = -im_i\n",
    "    idx_peak = int(np.argmax(neg_im))\n",
    "    F1 = re_i[0]; F2 = re_i[idx_peak]; F3 = re_i[-1]\n",
    "    sc = np.where(np.sign(im_i[:-1]) != np.sign(im_i[1:]))[0]\n",
    "    if len(sc):\n",
    "        k = sc[0]; y0,y1 = im_i[k], im_i[k+1]\n",
    "        w = -y0/(y1 - y0 + 1e-12)\n",
    "        F4 = re_i[k] + w*(re_i[k+1]-re_i[k])\n",
    "    else:\n",
    "        F4 = np.nan\n",
    "    F5 = (re_i[idx_peak]-F1) if idx_peak>0 else np.nan\n",
    "    F6 = np.min(im_i)\n",
    "    mid_target = 10.0\n",
    "    idx_mid = int(np.argmin(np.abs(freq-mid_target)))\n",
    "    F7 = re_i[idx_mid]\n",
    "    return [F1,F2,F3,F4,F5,F6,F7]\n",
    "\n",
    "PHYSICAL_FEATURE_NAMES = [\n",
    "    \"Rs\",\"Rct\",\"tau_peak\",\"warburg_sigma\",\"arc_quality\",\n",
    "    \"phase_mean_mid\",\"phase_std_mid\",\"phase_min\",\"lf_slope_negIm\",\"norm_arc\"\n",
    "]\n",
    "\n",
    "def physical_features(freq, re_i, im_i):\n",
    "    freq = np.asarray(freq); re_i = np.asarray(re_i); im_i = np.asarray(im_i)\n",
    "    neg_im = -im_i\n",
    "    idx_peak = int(np.argmax(neg_im))\n",
    "    Rs = float(re_i[0]); Rpeak = float(re_i[idx_peak]); Rlow = float(re_i[-1])\n",
    "    Rct = max(Rpeak - Rs, 0.0)\n",
    "    arc_diam = Rlow - Rs\n",
    "    norm_arc = arc_diam / (Rs + 1e-9)\n",
    "    f_peak = float(freq[idx_peak])\n",
    "    tau_peak = 1.0/(2*math.pi*f_peak) if f_peak>0 else np.nan\n",
    "    K = min(10, len(freq)//3)\n",
    "    if K >= 4:\n",
    "        w_section = (2*np.pi*freq[-K:])**(-0.5)\n",
    "        re_section = re_i[-K:]\n",
    "        if len(np.unique(w_section)) > 2:\n",
    "            warburg_sigma = float(np.polyfit(w_section, re_section, 1)[0])\n",
    "        else:\n",
    "            warburg_sigma = np.nan\n",
    "    else:\n",
    "        warburg_sigma = np.nan\n",
    "    phase = np.arctan2(-im_i, re_i)\n",
    "    mid_mask = (freq>=1) & (freq<=100)\n",
    "    if mid_mask.sum()>2:\n",
    "        phase_mean_mid = float(phase[mid_mask].mean())\n",
    "        phase_std_mid  = float(phase[mid_mask].std())\n",
    "    else:\n",
    "        phase_mean_mid = np.nan; phase_std_mid = np.nan\n",
    "    phase_min = float(phase.min())\n",
    "    lf_mask = (freq<=1.0)\n",
    "    if lf_mask.sum() >= 4:\n",
    "        x = np.log10(freq[lf_mask]+1e-12); y = neg_im[lf_mask]\n",
    "        lf_slope = np.polyfit(x, y, 1)[0]\n",
    "    else:\n",
    "        lf_slope = np.nan\n",
    "    arc_quality = (neg_im.max() - neg_im.min())/(abs(neg_im.mean())+1e-9)\n",
    "    return [Rs,Rct,tau_peak,warburg_sigma,arc_quality,\n",
    "            phase_mean_mid,phase_std_mid,phase_min,lf_slope,norm_arc]\n",
    "\n",
    "BANDS = [(1e4,1e3),(1e3,1e2),(1e2,10),(10,1),(1,1e-1),(1e-1,1e-2)]\n",
    "def band_stats(freq, re_i, im_i):\n",
    "    feats=[]; freq=np.asarray(freq)\n",
    "    for hi,lo in BANDS:\n",
    "        m=(freq<=hi)&(freq>=lo)\n",
    "        if m.sum()>1:\n",
    "            z=np.hypot(re_i[m], im_i[m])\n",
    "            feats += [z.mean(), z.std()]\n",
    "        else:\n",
    "            feats += [np.nan, np.nan]\n",
    "    return feats\n",
    "\n",
    "def diff_slopes(freq, re_i, im_i, segments=5):\n",
    "    logf = np.log10(freq)\n",
    "    edges = np.linspace(logf.min(), logf.max(), segments+1)\n",
    "    out=[]\n",
    "    for i in range(segments):\n",
    "        m=(logf>=edges[i])&(logf<=edges[i+1])\n",
    "        if m.sum()>=3:\n",
    "            x=logf[m]\n",
    "            out += [np.polyfit(x,re_i[m],1)[0], np.polyfit(x,(-im_i)[m],1)[0]]\n",
    "        else:\n",
    "            out += [np.nan, np.nan]\n",
    "    return out\n",
    "\n",
    "DRT_FEATURE_NAMES = [\n",
    "    \"drt_sum\",\"drt_mean_logtau\",\"drt_var_logtau\",\"drt_peak_tau\",\n",
    "    \"drt_peak_gamma\",\"drt_frac_low_tau\",\"drt_frac_high_tau\"\n",
    "]\n",
    "\n",
    "def compute_drt(freq,re_i,im_i,tau_min,tau_max,n_tau,lam):\n",
    "    w = 2*np.pi*freq\n",
    "    tau = np.geomspace(tau_max, tau_min, n_tau)\n",
    "    WT = w[:,None]*tau[None,:]\n",
    "    denom = 1+WT**2\n",
    "    K_re = 1.0/denom\n",
    "    K_im = -WT/denom\n",
    "    R_inf = re_i[0]\n",
    "    y_re = re_i - R_inf\n",
    "    y_im = im_i\n",
    "    Y = np.concatenate([y_re, y_im])\n",
    "    K = np.vstack([K_re, K_im])\n",
    "    A = K.T @ K + lam*np.eye(n_tau)\n",
    "    b = K.T @ Y\n",
    "    gamma = linalg.solve(A,b,assume_a='pos')\n",
    "    gamma = np.clip(gamma,0,None)\n",
    "    return tau, gamma\n",
    "\n",
    "def drt_features(freq,re_i,im_i):\n",
    "    try:\n",
    "        tau,gamma = compute_drt(freq,re_i,im_i,\n",
    "                                 cfg.DRT_TAU_MIN,cfg.DRT_TAU_MAX,\n",
    "                                 cfg.DRT_POINTS,cfg.DRT_LAMBDA)\n",
    "        log_tau = np.log10(tau)\n",
    "        g_sum = gamma.sum()+1e-12\n",
    "        w_norm = gamma/g_sum\n",
    "        mean_logtau = float((w_norm*log_tau).sum())\n",
    "        var_logtau  = float((w_norm*(log_tau-mean_logtau)**2).sum())\n",
    "        p = int(np.argmax(gamma))\n",
    "        peak_tau = float(tau[p]); peak_gamma=float(gamma[p])\n",
    "        mid = np.median(log_tau)\n",
    "        frac_low = float(w_norm[log_tau<=mid].sum())\n",
    "        frac_high = 1-frac_low\n",
    "        return [g_sum,mean_logtau,var_logtau,peak_tau,peak_gamma,frac_low,frac_high]\n",
    "    except Exception:\n",
    "        return [np.nan]*7\n",
    "\n",
    "def build_feature_vector(re_i, im_i, temp, freq, include_names=False):\n",
    "    parts=[]; names=[]\n",
    "    if cfg.INCLUDE_RAW_RE_IM:\n",
    "        parts += [re_i, im_i]\n",
    "        names += [f\"Re_{i}\" for i in range(len(re_i))] + [f\"Im_{i}\" for i in range(len(im_i))]\n",
    "    if cfg.INCLUDE_BASICS:\n",
    "        z = np.hypot(re_i, im_i)\n",
    "        basics=[re_i[0], re_i[-1], re_i[-1]-re_i[0], z.max(), z.mean(), z.std()]\n",
    "        parts.append(np.array(basics)); names += [\"hf_re\",\"lf_re\",\"arc_diam\",\"zmag_max\",\"zmag_mean\",\"zmag_std\"]\n",
    "    if cfg.INCLUDE_F_FEATS:\n",
    "        Ff=compute_F_features(freq,re_i,im_i); parts.append(np.array(Ff)); names += [f\"F{i}\" for i in range(1,8)]\n",
    "    if cfg.INCLUDE_PHYSICAL:\n",
    "        Pf=physical_features(freq,re_i,im_i); parts.append(np.array(Pf)); names += PHYSICAL_FEATURE_NAMES\n",
    "    if cfg.INCLUDE_BAND_STATS:\n",
    "        Bf=band_stats(freq,re_i,im_i); parts.append(np.array(Bf))\n",
    "        for bi in range(len(BANDS)): names += [f\"band{bi}_mean\", f\"band{bi}_std\"]\n",
    "    if cfg.INCLUDE_DIFF_SLOPES:\n",
    "        Ds=diff_slopes(freq,re_i,im_i); parts.append(np.array(Ds))\n",
    "        for i in range(len(Ds)//2): names += [f\"slope_re_seg{i}\", f\"slope_negIm_seg{i}\"]\n",
    "    if cfg.INCLUDE_DRT:\n",
    "        Df=drt_features(freq,re_i,im_i); parts.append(np.array(Df)); names += DRT_FEATURE_NAMES\n",
    "    parts.append(np.array([temp])); names += [\"Feat_Temp\"]\n",
    "    vec = np.concatenate(parts).astype(float)\n",
    "    vec = np.nan_to_num(vec, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    if include_names: return vec, names\n",
    "    return vec\n",
    "\n",
    "def build_shape_normalized(re_i, im_i, k: int = 5):\n",
    "    # Use median of the K highest-frequency Re points as HF scale (robust to noise/missing HF)\n",
    "    hf = float(np.nanmedian(re_i[:max(1, min(k, len(re_i)))]))\n",
    "    if not np.isfinite(hf) or abs(hf) < 1e-9:\n",
    "        hf = 1.0\n",
    "    return re_i / hf, im_i / hf\n",
    "\n",
    "# =========================\n",
    "# 7. CAPACITY & CPP\n",
    "# =========================\n",
    "def load_capacity_info(cap_dir: Path) -> pd.DataFrame:\n",
    "    if not (cap_dir.exists() and cfg.REFINE_SOH_WITH_CAPACITY):\n",
    "        return pd.DataFrame()\n",
    "    recs=[]\n",
    "    for fp in cap_dir.rglob(\"*.mat\"):\n",
    "        meta = parse_cap_metadata(fp.stem)\n",
    "        if not meta: continue\n",
    "        try:\n",
    "            mat=loadmat(fp); arr=_find_matrix(mat)\n",
    "            if arr is None: continue\n",
    "            col=np.argmax(np.abs(arr[-50:, :]).mean(axis=0))\n",
    "            cap=float(np.nanmax(arr[:,col]))\n",
    "            meta[\"MeasuredCapacity_Ah\"]=cap\n",
    "            recs.append(meta)\n",
    "        except Exception:\n",
    "            pass\n",
    "    df=pd.DataFrame(recs)\n",
    "    if df.empty: return df\n",
    "    ref=df.groupby(\"CellID\")[\"MeasuredCapacity_Ah\"].transform(\"max\")\n",
    "    df[\"NormCapacity\"]=df[\"MeasuredCapacity_Ah\"]/ref\n",
    "    df[\"SoH_percent\"]=df[\"NormCapacity\"]*100.0\n",
    "    return df\n",
    "\n",
    "def estimate_cpp_per_cell(capacity_df: pd.DataFrame,\n",
    "                          window:int, min_points:int)->Dict[str,float]:\n",
    "    cpp={}\n",
    "    for cid,grp in capacity_df.groupby(\"CellID\"):\n",
    "        g=grp.sort_values(\"CycleIndex\")\n",
    "        if g.shape[0]<min_points: continue\n",
    "        tail=g.tail(window)\n",
    "        x=tail[\"CycleIndex\"].values.astype(float)\n",
    "        y=tail[\"SoH_percent\"].values.astype(float)\n",
    "        if len(np.unique(x))<2: continue\n",
    "        slope=np.polyfit(x,y,1)[0]  # SoH% / cycle\n",
    "        if slope >= -1e-6:  # non-degrading\n",
    "            continue\n",
    "        cpp[cid]=1.0/abs(slope)\n",
    "    return cpp\n",
    "\n",
    "def build_cpp_map(cap_df: pd.DataFrame):\n",
    "    if cap_df.empty: return {}, cfg.CPP_FALLBACK\n",
    "    cpp_map=estimate_cpp_per_cell(\n",
    "        cap_df[[\"CellID\",\"CycleIndex\",\"SoH_percent\"]],\n",
    "        cfg.CPP_ROLLING_WINDOW, cfg.CPP_MIN_POINTS\n",
    "    )\n",
    "    if not cpp_map:\n",
    "        return {}, cfg.CPP_FALLBACK\n",
    "    return cpp_map, float(np.median(list(cpp_map.values())))\n",
    "\n",
    "def get_cpp(meta: dict, cpp_map: Dict[str,float], global_cpp: float):\n",
    "    if not meta: return global_cpp\n",
    "    return cpp_map.get(meta.get(\"CellID\"), global_cpp)\n",
    "\n",
    "# =========================\n",
    "# 8. DATASET BUILD (training on .mat only)\n",
    "# =========================\n",
    "def load_single_eis_mat(fp: Path):\n",
    "    meta = parse_eis_metadata(fp.stem)\n",
    "    if meta is None:\n",
    "        raise ValueError(f\"Bad filename: {fp.name}\")\n",
    "    freq,re_z,im_z = load_mat_eis(fp)\n",
    "    re_i=_interp_channel(freq, re_z, CANON_FREQ)\n",
    "    im_i=_interp_channel(freq, im_z, CANON_FREQ)\n",
    "    vec=build_feature_vector(re_i, im_i, meta[\"Temp\"], CANON_FREQ)\n",
    "    return vec, meta, re_i, im_i\n",
    "\n",
    "def build_dataset(eis_dir: Path, cap_df: Optional[pd.DataFrame]):\n",
    "    files = sorted(eis_dir.rglob(\"*.mat\"))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No .mat spectra in {eis_dir}\")\n",
    "\n",
    "    f0,r0,i0 = load_mat_eis(files[0])\n",
    "    re0=_interp_channel(f0,r0,CANON_FREQ); im0=_interp_channel(f0,i0,CANON_FREQ)\n",
    "    _, feature_names = build_feature_vector(re0, im0, 25.0, CANON_FREQ, include_names=True)\n",
    "\n",
    "    feats=[]; rows=[]; shape_feats=[]\n",
    "    for fp in tqdm(files, desc=\"Loading training spectra\"):\n",
    "        try:\n",
    "            v, m, rei, imi = load_single_eis_mat(fp)\n",
    "            feats.append(v); rows.append(m)\n",
    "            if (cfg.INCLUDE_NORMALIZED_SHAPE_MODEL or cfg.SOC_INCLUDE_SHAPE_MODEL) and cfg.NORMALIZE_SHAPE_BY_HF_RE:\n",
    "                rsh, ish = build_shape_normalized(rei, imi)\n",
    "                shape_vec = build_feature_vector(rsh, ish, m[\"Temp\"], CANON_FREQ)\n",
    "                shape_feats.append(shape_vec)\n",
    "        except Exception as e:\n",
    "            if cfg.VERBOSE: print(f\"[Skip] {fp.name}: {e}\")\n",
    "\n",
    "    if not rows:\n",
    "        raise RuntimeError(\"No valid training spectra after filtering.\")\n",
    "\n",
    "    X = np.vstack(feats)\n",
    "    X_shape = np.vstack(shape_feats) if shape_feats else None\n",
    "    meta_df = pd.DataFrame(rows)\n",
    "\n",
    "    # SoH refinement with capacity\n",
    "    if cap_df is not None and not cap_df.empty and cfg.REFINE_SOH_WITH_CAPACITY:\n",
    "        lookup = cap_df.set_index([\"CellID\",\"SOH_stage\"])[\"NormCapacity\"].to_dict()\n",
    "        refined=[]\n",
    "        for cid, stage, fallback in zip(meta_df.CellID, meta_df.SOH_stage, meta_df.RealSOH_file):\n",
    "            nc = lookup.get((cid, stage))\n",
    "            refined.append(100.0*nc if nc is not None else fallback)\n",
    "        meta_df[\"SoH_cont\"]=refined\n",
    "    else:\n",
    "        meta_df[\"SoH_cont\"]=meta_df[\"RealSOH_file\"]\n",
    "\n",
    "    # Targets\n",
    "    y_soc = meta_df[\"SOC\"].astype(float).values  # continuous SoC\n",
    "    y_soh = meta_df[\"SoH_cont\"].values\n",
    "\n",
    "    soh_var = float(np.var(y_soh))\n",
    "    if cfg.VERBOSE:\n",
    "        print(f\"[DATA] SoH range: {y_soh.min():.2f} – {y_soh.max():.2f} (var={soh_var:.3f})\")\n",
    "        if soh_var < 1.0:\n",
    "            print(\"[WARN] Low SoH variance → model may output near-constant SoH.\")\n",
    "\n",
    "    if cfg.SAVE_FEATURE_TABLE:\n",
    "        pd.concat(\n",
    "            [meta_df.reset_index(drop=True),\n",
    "             pd.DataFrame(X, columns=feature_names)], axis=1\n",
    "        ).to_parquet(cfg.MODEL_DIR/\"training_features.parquet\", index=False)\n",
    "\n",
    "    return meta_df, X, (X_shape, feature_names), y_soc, y_soh\n",
    "\n",
    "# =========================\n",
    "# 9. SPLITTING\n",
    "# =========================\n",
    "def cell_split_mask(meta_df: pd.DataFrame):\n",
    "    cells = meta_df.CellID.unique()\n",
    "    rng = np.random.default_rng(cfg.RANDOM_STATE)\n",
    "    n_test = max(1, int(len(cells)*cfg.TEST_FRAC))\n",
    "    test_cells = rng.choice(cells, size=n_test, replace=False)\n",
    "    return meta_df.CellID.isin(test_cells)\n",
    "\n",
    "# =========================\n",
    "# 10. TRAINING\n",
    "# =========================\n",
    "def _fit_gpr(X, y, seed, max_samples):\n",
    "    dim = X.shape[1]\n",
    "    kernel = RBF(length_scale=np.ones(dim)*3.0,\n",
    "                 length_scale_bounds=(1e-1,1e4)) + \\\n",
    "             WhiteKernel(noise_level=1e-2,\n",
    "                         noise_level_bounds=(1e-6,1e-1))\n",
    "    gpr = GaussianProcessRegressor(\n",
    "        kernel=kernel, alpha=0.0, normalize_y=True,\n",
    "        random_state=seed, n_restarts_optimizer=3\n",
    "    )\n",
    "    if X.shape[0] > max_samples:\n",
    "        idx = np.random.default_rng(seed).choice(\n",
    "            X.shape[0], size=max_samples, replace=False)\n",
    "        gpr.fit(X[idx], y[idx])\n",
    "    else:\n",
    "        gpr.fit(X, y)\n",
    "    return gpr\n",
    "\n",
    "def train_models(meta_df, X_raw, shape_bundle, y_soc, y_soh):\n",
    "    X_shape, feature_names = shape_bundle\n",
    "    mask_test = cell_split_mask(meta_df)\n",
    "\n",
    "    # ----- SoC pipeline (REGRESSION) -----\n",
    "    soc_scaler = StandardScaler()\n",
    "    X_soc_s = soc_scaler.fit_transform(X_raw)\n",
    "    soc_pca = None\n",
    "    X_soc_model = X_soc_s\n",
    "    if cfg.USE_PCA_SOC:\n",
    "        soc_pca = PCA(n_components=min(cfg.PCA_SOC_COMPONENTS, X_soc_s.shape[1]-1),\n",
    "                      random_state=cfg.RANDOM_STATE)\n",
    "        X_soc_model = soc_pca.fit_transform(X_soc_s)\n",
    "\n",
    "    soc_candidates = {}\n",
    "\n",
    "    # (1) SoC GPR (raw features)\n",
    "    soc_gpr = _fit_gpr(X_soc_model, y_soc, cfg.RANDOM_STATE, cfg.SOC_MAX_GPR_TRAIN_SAMPLES)\n",
    "    pred_soc_gpr = soc_gpr.predict(X_soc_model[mask_test])\n",
    "    r2_soc_gpr = r2_score(y_soc[mask_test], pred_soc_gpr)\n",
    "    rmse_soc_gpr = math.sqrt(mean_squared_error(y_soc[mask_test], pred_soc_gpr))\n",
    "    soc_candidates[\"soc_gpr_raw\"] = (soc_gpr, r2_soc_gpr, rmse_soc_gpr)\n",
    "\n",
    "    # (2) SoC HGB (raw features)\n",
    "    soc_hgb = HistGradientBoostingRegressor(\n",
    "        learning_rate=0.05, max_iter=500,\n",
    "        l2_regularization=1e-3, random_state=cfg.RANDOM_STATE\n",
    "    )\n",
    "    soc_hgb.fit(X_soc_model[~mask_test], y_soc[~mask_test])\n",
    "    pred_soc_hgb = soc_hgb.predict(X_soc_model[mask_test])\n",
    "    r2_soc_hgb = r2_score(y_soc[mask_test], pred_soc_hgb)\n",
    "    rmse_soc_hgb = math.sqrt(mean_squared_error(y_soc[mask_test], pred_soc_hgb))\n",
    "    soc_candidates[\"soc_hgb_raw\"] = (soc_hgb, r2_soc_hgb, rmse_soc_hgb)\n",
    "\n",
    "    # (3) Optional shape-normalized SoC GP\n",
    "    soc_shape_model=None; soc_shape_scaler=None; soc_shape_pca=None; soc_shape_metrics=None\n",
    "    if cfg.SOC_INCLUDE_SHAPE_MODEL and (X_shape is not None):\n",
    "        soc_shape_scaler = StandardScaler()\n",
    "        Xs = soc_shape_scaler.fit_transform(X_shape)\n",
    "        if cfg.USE_PCA_SOC:\n",
    "            soc_shape_pca = PCA(n_components=min(cfg.PCA_SOC_COMPONENTS, Xs.shape[1]-1),\n",
    "                                random_state=cfg.RANDOM_STATE)\n",
    "            Xs_model = soc_shape_pca.fit_transform(Xs)\n",
    "        else:\n",
    "            Xs_model = Xs\n",
    "        soc_shape_model = _fit_gpr(Xs_model, y_soc, cfg.RANDOM_STATE, cfg.SOC_MAX_GPR_TRAIN_SAMPLES)\n",
    "        sp = soc_shape_model.predict(Xs_model[mask_test])\n",
    "        r2_soc_shape = r2_score(y_soc[mask_test], sp)\n",
    "        rmse_soc_shape = math.sqrt(mean_squared_error(y_soc[mask_test], sp))\n",
    "        soc_candidates[\"soc_gpr_shape\"] = (soc_shape_model, r2_soc_shape, rmse_soc_shape)\n",
    "        soc_shape_metrics = {\"r2\": r2_soc_shape, \"rmse\": rmse_soc_shape}\n",
    "\n",
    "    # Select best SoC model\n",
    "    soc_best_name = max(soc_candidates.keys(), key=lambda k: soc_candidates[k][1])\n",
    "    soc_best_model, soc_best_r2, soc_best_rmse = soc_candidates[soc_best_name]\n",
    "\n",
    "    if cfg.VERBOSE:\n",
    "        print(f\"[SoC] GPR_raw:   R2={r2_soc_gpr:.3f} RMSE={rmse_soc_gpr:.2f}\")\n",
    "        print(f\"[SoC] HGB_raw:   R2={r2_soc_hgb:.3f} RMSE={rmse_soc_hgb:.2f}\")\n",
    "        if soc_shape_metrics:\n",
    "            print(f\"[SoC] ShapeGP:  R2={soc_shape_metrics['r2']:.3f} RMSE={soc_shape_metrics['rmse']:.2f}\")\n",
    "        print(f\"[SoC] Selected = {soc_best_name}\")\n",
    "\n",
    "    # ----- SoH pipeline (unchanged) -----\n",
    "    soh_scaler = StandardScaler()\n",
    "    X_soh_s = soh_scaler.fit_transform(X_raw)\n",
    "    soh_pca=None\n",
    "    X_soh_model = X_soh_s\n",
    "    if cfg.USE_PCA_SOH:\n",
    "        soh_pca = PCA(n_components=min(cfg.PCA_SOH_COMPONENTS, X_soh_s.shape[1]-1),\n",
    "                      random_state=cfg.RANDOM_STATE)\n",
    "        X_soh_model = soh_pca.fit_transform(X_soh_s)\n",
    "\n",
    "    soh_candidates = {}\n",
    "\n",
    "    # (1) Raw Gaussian Process\n",
    "    gpr = _fit_gpr(X_soh_model, y_soh, cfg.RANDOM_STATE, cfg.MAX_GPR_TRAIN_SAMPLES)\n",
    "    pred_gpr = gpr.predict(X_soh_model[mask_test])\n",
    "    r2_gpr = r2_score(y_soh[mask_test], pred_gpr)\n",
    "    rmse_gpr = math.sqrt(mean_squared_error(y_soh[mask_test], pred_gpr))\n",
    "    soh_candidates[\"gpr_raw\"] = (gpr, r2_gpr, rmse_gpr)\n",
    "\n",
    "    # (2) HistGradientBoosting\n",
    "    hgb = HistGradientBoostingRegressor(\n",
    "        learning_rate=0.05, max_iter=500,\n",
    "        l2_regularization=1e-3, random_state=cfg.RANDOM_STATE\n",
    "    )\n",
    "    hgb.fit(X_soh_model[~mask_test], y_soh[~mask_test])\n",
    "    pred_hgb = hgb.predict(X_soh_model[mask_test])\n",
    "    r2_hgb = r2_score(y_soh[mask_test], pred_hgb)\n",
    "    rmse_hgb = math.sqrt(mean_squared_error(y_soh[mask_test], pred_hgb))\n",
    "    soh_candidates[\"hgb_raw\"] = (hgb, r2_hgb, rmse_hgb)\n",
    "\n",
    "    # (3) Shape-normalized GP\n",
    "    shape_model = None; shape_scaler=None; shape_pca=None; shape_metrics=None\n",
    "    if cfg.INCLUDE_NORMALIZED_SHAPE_MODEL and (X_shape is not None):\n",
    "        shape_scaler = StandardScaler()\n",
    "        X_shape_s = shape_scaler.fit_transform(X_shape)\n",
    "        X_shape_model = X_shape_s\n",
    "        if cfg.USE_PCA_SOH:\n",
    "            shape_pca = PCA(n_components=min(cfg.PCA_SOH_COMPONENTS, X_shape_s.shape[1]-1),\n",
    "                            random_state=cfg.RANDOM_STATE)\n",
    "            X_shape_model = shape_pca.fit_transform(X_shape_s)\n",
    "        shape_model = _fit_gpr(X_shape_model, y_soh, cfg.RANDOM_STATE, cfg.MAX_GPR_TRAIN_SAMPLES)\n",
    "        spred = shape_model.predict(X_shape_model[mask_test])\n",
    "        r2_shape = r2_score(y_soh[mask_test], spred)\n",
    "        rmse_shape = math.sqrt(mean_squared_error(y_soh[mask_test], spred))\n",
    "        soh_candidates[\"gpr_shape\"] = (shape_model, r2_shape, rmse_shape)\n",
    "        shape_metrics = {\"r2\": r2_shape, \"rmse\": rmse_shape}\n",
    "\n",
    "    best_name = max([\"gpr_raw\",\"hgb_raw\"], key=lambda k: soh_candidates[k][1])\n",
    "    best_model, best_r2, best_rmse = soh_candidates[best_name]\n",
    "\n",
    "    if cfg.VERBOSE:\n",
    "        print(f\"[SoH] GPR_raw:  R2={r2_gpr:.3f} RMSE={rmse_gpr:.2f}\")\n",
    "        print(f\"[SoH] HGB_raw:  R2={r2_hgb:.3f} RMSE={rmse_hgb:.2f}\")\n",
    "        if shape_metrics:\n",
    "            print(f\"[SoH] ShapeGP: R2={shape_metrics['r2']:.3f} RMSE={shape_metrics['rmse']:.2f}\")\n",
    "        print(f\"[SoH] Selected raw model = {best_name}\")\n",
    "\n",
    "    # Mahalanobis precomputed on scaled raw SoH space\n",
    "    cov = np.cov(X_soh_s.T)\n",
    "    try:\n",
    "        cov_inv = np.linalg.pinv(cov)\n",
    "    except Exception:\n",
    "        cov_inv = np.eye(cov.shape[0])\n",
    "    center = X_soh_s.mean(axis=0)\n",
    "\n",
    "    bundle = {\n",
    "        # SoC (regression)\n",
    "        \"soc_scaler\": soc_scaler,\n",
    "        \"soc_pca\": soc_pca,\n",
    "        \"soc_model\": soc_best_model,\n",
    "        \"soc_model_name\": soc_best_name,\n",
    "        \"soc_shape_scaler\": soc_shape_scaler,\n",
    "        \"soc_shape_pca\": soc_shape_pca,\n",
    "        \"soc_shape_model\": soc_shape_model,\n",
    "\n",
    "        # SoH\n",
    "        \"soh_scaler\": soh_scaler,\n",
    "        \"soh_pca\": soh_pca,\n",
    "        \"soh_model\": best_model,\n",
    "        \"soh_model_name\": best_name,\n",
    "\n",
    "        # Optional SoH shape model\n",
    "        \"shape_scaler\": shape_scaler,\n",
    "        \"shape_pca\": shape_pca,\n",
    "        \"shape_model\": shape_model,\n",
    "\n",
    "        # Meta\n",
    "        \"freq_grid\": CANON_FREQ,\n",
    "        \"feature_version\": cfg.FEATURE_VERSION,\n",
    "        \"feature_manifest\": feature_names,\n",
    "        \"config\": to_jsonable(asdict(cfg)),\n",
    "        \"metrics\": {\n",
    "            \"soc_r2_selected\": soc_best_r2,\n",
    "            \"soc_rmse_selected\": soc_best_rmse,\n",
    "            \"soh_r2_selected\": best_r2,\n",
    "            \"soh_rmse_selected\": best_rmse\n",
    "        },\n",
    "        \"soc_candidates_metrics\": {\n",
    "            \"soc_gpr_raw\": {\"r2\": r2_soc_gpr, \"rmse\": rmse_soc_gpr},\n",
    "            \"soc_hgb_raw\": {\"r2\": r2_soc_hgb, \"rmse\": rmse_soc_hgb},\n",
    "            \"soc_gpr_shape\": soc_shape_metrics\n",
    "        },\n",
    "        \"soh_candidates_metrics\": {\n",
    "            \"gpr_raw\": {\"r2\": r2_gpr, \"rmse\": rmse_gpr},\n",
    "            \"hgb_raw\": {\"r2\": r2_hgb, \"rmse\": rmse_hgb},\n",
    "            \"gpr_shape\": shape_metrics\n",
    "        },\n",
    "        \"train_mahal\": {\"center\": center.tolist(), \"cov_inv\": cov_inv.tolist()}\n",
    "    }\n",
    "    out_path = cfg.MODEL_DIR/\"eis_soc_soh_phys_models.joblib\"\n",
    "    joblib.dump(bundle, out_path)\n",
    "    if cfg.VERBOSE:\n",
    "        print(f\"[MODEL] Saved bundle → {out_path}\")\n",
    "        print(json.dumps(bundle[\"metrics\"], indent=2))\n",
    "    return bundle\n",
    "\n",
    "# =========================\n",
    "# 11. LOAD (WITH LEGACY COMPATIBILITY SHIM)\n",
    "# =========================\n",
    "def load_bundle():\n",
    "    \"\"\"\n",
    "    Legacy schema keys:\n",
    "        \"scaler\", \"pca\", \"soc_model\", \"soh_model\"\n",
    "    New schema keys (v8):\n",
    "        SoC regression keys: \"soc_scaler\",\"soc_pca\",\"soc_model\",\"soc_model_name\",...\n",
    "    \"\"\"\n",
    "    path = cfg.MODEL_DIR / \"eis_soc_soh_phys_models.joblib\"\n",
    "    bundle = joblib.load(path)\n",
    "\n",
    "    # Legacy detection: older single scaler/pca, possibly classifier SoC model\n",
    "    legacy = (\"scaler\" in bundle) and (\"soc_scaler\" not in bundle)\n",
    "    if legacy:\n",
    "        scaler = bundle[\"scaler\"]\n",
    "        pca = bundle.get(\"pca\")\n",
    "        soc_model = bundle.get(\"soc_model\")   # may be classifier\n",
    "        soh_model = bundle.get(\"soh_model\")\n",
    "\n",
    "        bundle[\"soc_scaler\"] = scaler\n",
    "        bundle[\"soh_scaler\"] = scaler\n",
    "        bundle[\"soc_pca\"]    = pca\n",
    "        bundle[\"soh_pca\"]    = pca\n",
    "        bundle[\"soh_model\"]  = soh_model\n",
    "        # best guess name\n",
    "        name = bundle.get(\"soh_model_name\",\"legacy_model\")\n",
    "        bundle[\"soh_model_name\"] = name\n",
    "        # mark unknown SoC model type; handled in inference\n",
    "        bundle[\"soc_model_name\"] = bundle.get(\"soc_model_name\",\"legacy_soc_model\")\n",
    "        if \"metrics\" not in bundle:\n",
    "            bundle[\"metrics\"] = {}\n",
    "        bundle[\"metrics\"].setdefault(\"soh_rmse_selected\", 5.0)\n",
    "        bundle[\"metrics\"].setdefault(\"soc_rmse_selected\", 8.0)  # coarse fallback\n",
    "        if \"train_mahal\" not in bundle:\n",
    "            try:\n",
    "                center = scaler.mean_\n",
    "                cov_inv = np.eye(len(center))\n",
    "                bundle[\"train_mahal\"] = {\"center\": center.tolist(), \"cov_inv\": cov_inv.tolist()}\n",
    "            except Exception:\n",
    "                bundle[\"train_mahal\"] = None\n",
    "        bundle.setdefault(\"feature_version\", -1)\n",
    "\n",
    "    # Sanity check\n",
    "    for key in [\"soc_scaler\",\"soc_model\",\"soh_scaler\",\"soh_model\",\"freq_grid\"]:\n",
    "        if key not in bundle:\n",
    "            raise KeyError(f\"Bundle missing required key: {key}\")\n",
    "\n",
    "    return bundle\n",
    "\n",
    "# =========================\n",
    "# 12. INFERENCE FEATURIZATION\n",
    "# =========================\n",
    "def featurize_any(file_path: Path, bundle):\n",
    "    freq_grid = bundle[\"freq_grid\"]\n",
    "    meta = parse_eis_metadata(file_path.stem)\n",
    "    freq,re_raw,im_raw = load_any_inference(file_path)\n",
    "    re_i=_interp_channel(freq, re_raw, freq_grid)\n",
    "    im_i=_interp_channel(freq, im_raw, freq_grid)\n",
    "    if meta is None and cfg.TEST_TEMPERATURE_OVERRIDE is not None:\n",
    "        temp = cfg.TEST_TEMPERATURE_OVERRIDE\n",
    "    else:\n",
    "        temp = meta[\"Temp\"] if meta else -1\n",
    "    vec = build_feature_vector(re_i, im_i, temp, freq_grid)\n",
    "    norm_vec=None\n",
    "    if (cfg.INCLUDE_NORMALIZED_SHAPE_MODEL or cfg.SOC_INCLUDE_SHAPE_MODEL) and \\\n",
    "       (bundle.get(\"shape_model\") is not None or bundle.get(\"soc_shape_model\") is not None):\n",
    "        if cfg.NORMALIZE_SHAPE_BY_HF_RE:\n",
    "            rsh, ish = build_shape_normalized(re_i, im_i)\n",
    "            norm_vec = build_feature_vector(rsh, ish, temp, freq_grid)\n",
    "    return vec, norm_vec, meta\n",
    "\n",
    "# =========================\n",
    "# 13. OOD UTILITIES\n",
    "# =========================\n",
    "def mahalanobis_distance(x, center, cov_inv):\n",
    "    diff = x - center\n",
    "    return float(np.sqrt(diff @ cov_inv @ diff.T))\n",
    "\n",
    "def gp_ard_norm(Xp, model):\n",
    "    try:\n",
    "        K = model.kernel_\n",
    "        from sklearn.gaussian_process.kernels import RBF\n",
    "        rbf = None\n",
    "        if hasattr(K,\"k1\") and isinstance(K.k1,RBF): rbf=K.k1\n",
    "        elif hasattr(K,\"k2\") and isinstance(K.k2,RBF): rbf=K.k2\n",
    "        if rbf is None: return None\n",
    "        ls = np.atleast_1d(rbf.length_scale)\n",
    "        z = (Xp / ls).ravel()\n",
    "        return float(np.linalg.norm(z))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# =========================\n",
    "# 14. PROJECTION PLOT\n",
    "# =========================\n",
    "def build_projection(soh_current, cpp, lower, exponent=None, n=160):\n",
    "    if soh_current <= lower or cpp <= 0:\n",
    "        return np.array([0.0]), np.array([soh_current])\n",
    "    total = (soh_current - lower) * cpp\n",
    "    cycles = np.linspace(0, total, n)\n",
    "    S0 = soh_current; Smin=lower\n",
    "    if exponent is None: exponent = cfg.PLOT_EXPONENT\n",
    "    soh_curve = Smin + (S0 - Smin)*(1 - cycles/total)**exponent\n",
    "    return cycles, soh_curve\n",
    "\n",
    "def plot_projection(file_base, soh_current, soh_std, cycles_to_target,\n",
    "                    cycles_to_lower, cpp, ood_flag, out_path):\n",
    "    if cycles_to_lower <= 0:\n",
    "        return\n",
    "    cycles, curve = build_projection(soh_current, cpp, cfg.ILLUSTRATIVE_MIN_SOH)\n",
    "    plt.figure(figsize=(6.4,4))\n",
    "    plt.plot(cycles, curve, lw=2, label=\"Projected SoH\")\n",
    "    plt.axhline(cfg.DECISION_SOH_PERCENT, color=\"orange\", ls=\"--\", label=f\"{cfg.DECISION_SOH_PERCENT:.0f}% target\")\n",
    "    plt.axhline(cfg.ILLUSTRATIVE_MIN_SOH, color=\"red\", ls=\":\", label=f\"{cfg.ILLUSTRATIVE_MIN_SOH:.0f}% lower\")\n",
    "    plt.scatter([0],[soh_current], c=\"green\", s=55, label=f\"Current {soh_current:.2f}%\")\n",
    "    plt.text(0, soh_current+0.7, f\"±{soh_std:.2f}\", color=\"green\", fontsize=8)\n",
    "    if cycles_to_target > 0:\n",
    "        plt.axvline(cycles_to_target, color=\"orange\", ls=\"-.\")\n",
    "        plt.scatter([cycles_to_target],[cfg.DECISION_SOH_PERCENT], c=\"orange\", s=45)\n",
    "        plt.text(cycles_to_target, cfg.DECISION_SOH_PERCENT+1.0,\n",
    "                 f\"{cycles_to_target:.0f} cyc\", ha=\"center\", color=\"orange\", fontsize=8)\n",
    "    plt.scatter([cycles[-1]],[cfg.ILLUSTRATIVE_MIN_SOH], c=\"red\", s=50)\n",
    "    plt.text(cycles[-1], cfg.ILLUSTRATIVE_MIN_SOH-2,\n",
    "             f\"{cycles[-1]:.0f} cyc\", ha=\"center\", color=\"red\", fontsize=8)\n",
    "    if ood_flag:\n",
    "        plt.text(0.98,0.05,\"OOD\", transform=plt.gca().transAxes,\n",
    "                 ha=\"right\", va=\"bottom\", color=\"crimson\", fontsize=11,\n",
    "                 bbox=dict(boxstyle=\"round\", fc=\"w\", ec=\"crimson\"))\n",
    "    plt.xlabel(\"Remaining Cycles\")\n",
    "    plt.ylabel(\"SoH (%)\")\n",
    "    plt.title(f\"RUL Projection – {file_base}\")\n",
    "    plt.grid(alpha=0.35)\n",
    "    plt.legend(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=140)\n",
    "    plt.close()\n",
    "\n",
    "# =========================\n",
    "# 15. INFERENCE (SINGLE FILE)\n",
    "# =========================\n",
    "def predict_file(file_path: Path, bundle, cpp_map, global_cpp):\n",
    "    vec, norm_vec, meta = featurize_any(file_path, bundle)\n",
    "\n",
    "    # ----- SoC (regression now; legacy classifier supported) -----\n",
    "    soc_scaler=bundle[\"soc_scaler\"]; soc_pca=bundle.get(\"soc_pca\")\n",
    "    soc_model=bundle[\"soc_model\"]; soc_model_name=bundle.get(\"soc_model_name\",\"unknown\")\n",
    "    X_soc = soc_scaler.transform(vec.reshape(1,-1))\n",
    "    X_soc_in = soc_pca.transform(X_soc) if soc_pca else X_soc\n",
    "\n",
    "    soc_probs = None\n",
    "    # Legacy classifier path: if predict_proba exists, use it and also output a continuous estimate by class-prob expectation\n",
    "    if hasattr(soc_model, \"predict_proba\"):\n",
    "        p = soc_model.predict_proba(X_soc_in)[0]\n",
    "        # Try to read class labels (assumed numeric percent levels)\n",
    "        classes = getattr(soc_model, \"classes_\", np.arange(len(p)))\n",
    "        classes = np.array(classes, dtype=float)\n",
    "        soc_mean = float(np.dot(p, classes))\n",
    "        # std as categorical variance proxy\n",
    "        var = float(np.dot(p, (classes - soc_mean)**2))\n",
    "        soc_std = math.sqrt(var) if var>0 else float(bundle[\"metrics\"].get(\"soc_rmse_selected\", 8.0))\n",
    "        soc_probs = {float(c): float(pp) for c,pp in zip(classes,p)}\n",
    "    else:\n",
    "        # Regression path\n",
    "        if isinstance(soc_model, GaussianProcessRegressor):\n",
    "            sm, ss = soc_model.predict(X_soc_in, return_std=True)\n",
    "            soc_mean = float(sm[0]); soc_std=float(ss[0])\n",
    "        else:\n",
    "            soc_mean = float(soc_model.predict(X_soc_in)[0])\n",
    "            soc_std  = float(bundle[\"metrics\"].get(\"soc_rmse_selected\", 8.0))\n",
    "\n",
    "        # If a shape SoC model exists, average (ensemble) for robustness\n",
    "        soc_shape_model = bundle.get(\"soc_shape_model\")\n",
    "        if soc_shape_model is not None and norm_vec is not None:\n",
    "            sscaler = bundle.get(\"soc_shape_scaler\"); spca = bundle.get(\"soc_shape_pca\")\n",
    "            Xs = sscaler.transform(norm_vec.reshape(1,-1))\n",
    "            Xs_in = spca.transform(Xs) if spca else Xs\n",
    "            if isinstance(soc_shape_model, GaussianProcessRegressor):\n",
    "                sm2, ss2 = soc_shape_model.predict(Xs_in, return_std=True)\n",
    "                mean2=float(sm2[0]); std2=float(ss2[0])\n",
    "            else:\n",
    "                mean2=float(soc_shape_model.predict(Xs_in)[0]); std2=float(bundle[\"metrics\"].get(\"soc_rmse_selected\", 8.0))\n",
    "            soc_mean = 0.5*(soc_mean + mean2)\n",
    "            soc_std  = float(np.sqrt(0.5*(soc_std**2 + std2**2)))\n",
    "\n",
    "    # ----- SoH (raw primary + optional shape ensemble) -----\n",
    "    soh_scaler=bundle[\"soh_scaler\"]; soh_pca=bundle.get(\"soh_pca\")\n",
    "    soh_model=bundle[\"soh_model\"]; model_name=bundle.get(\"soh_model_name\",\"unknown\")\n",
    "    X_soh_s = soh_scaler.transform(vec.reshape(1,-1))\n",
    "    X_soh_in = soh_pca.transform(X_soh_s) if soh_pca else X_soh_s\n",
    "\n",
    "    if \"gpr\" in model_name:\n",
    "        sm, ss = soh_model.predict(X_soh_in, return_std=True)\n",
    "        soh_mean_raw = float(sm[0]); soh_std_raw=float(ss[0])\n",
    "    else:\n",
    "        soh_mean_raw = float(soh_model.predict(X_soh_in)[0])\n",
    "        soh_std_raw  = float(bundle[\"metrics\"].get(\"soh_rmse_selected\", 5.0))\n",
    "\n",
    "    shape_model = bundle.get(\"shape_model\")\n",
    "    shape_soh_mean=None; shape_soh_std=None\n",
    "    if shape_model is not None and norm_vec is not None:\n",
    "        sscaler = bundle.get(\"shape_scaler\")\n",
    "        spca = bundle.get(\"shape_pca\")\n",
    "        X_shape_s = sscaler.transform(norm_vec.reshape(1,-1))\n",
    "        X_shape_in = spca.transform(X_shape_s) if spca else X_shape_s\n",
    "        if isinstance(shape_model, GaussianProcessRegressor):\n",
    "            sm2, ss2 = shape_model.predict(X_shape_in, return_std=True)\n",
    "            shape_soh_mean=float(sm2[0]); shape_soh_std=float(ss2[0])\n",
    "        else:\n",
    "            shape_soh_mean=float(shape_model.predict(X_shape_in)[0])\n",
    "            shape_soh_std=float(bundle[\"metrics\"].get(\"soh_rmse_selected\", 5.0))\n",
    "\n",
    "    if cfg.ENSEMBLE_SOH and shape_soh_mean is not None:\n",
    "        soh_mean = 0.5*(soh_mean_raw + shape_soh_mean)\n",
    "        stds = [soh_std_raw]\n",
    "        if shape_soh_std is not None: stds.append(shape_soh_std)\n",
    "        soh_std = float(np.sqrt(np.mean(np.array(stds)**2)))\n",
    "    else:\n",
    "        soh_mean, soh_std = soh_mean_raw, soh_std_raw\n",
    "\n",
    "    # RUL\n",
    "    cpp = get_cpp(meta, cpp_map, global_cpp)\n",
    "    if soh_mean > cfg.DECISION_SOH_PERCENT:\n",
    "        cycles_to_target = (soh_mean - cfg.DECISION_SOH_PERCENT)*cpp\n",
    "    else:\n",
    "        cycles_to_target = 0.0\n",
    "    if soh_mean > cfg.ILLUSTRATIVE_MIN_SOH:\n",
    "        cycles_to_lower = (soh_mean - cfg.ILLUSTRATIVE_MIN_SOH)*cpp\n",
    "    else:\n",
    "        cycles_to_lower = 0.0\n",
    "\n",
    "    # OOD diagnostics (based on SoH space)\n",
    "    train_mahal = bundle.get(\"train_mahal\")\n",
    "    mahal_dist=None\n",
    "    if train_mahal:\n",
    "        cov_inv = np.array(train_mahal[\"cov_inv\"])\n",
    "        center = np.array(train_mahal[\"center\"])\n",
    "        mahal_dist = mahalanobis_distance(X_soh_s[0], center, cov_inv)\n",
    "    ard_norm=None\n",
    "    if \"gpr\" in model_name:\n",
    "        ard_norm = gp_ard_norm(X_soh_in, soh_model)\n",
    "    ood_flag=False\n",
    "    if (mahal_dist is not None and mahal_dist > cfg.MAHAL_THRESHOLD) or \\\n",
    "       (ard_norm is not None and ard_norm > cfg.GP_ARD_NORM_THRESHOLD):\n",
    "        ood_flag=True\n",
    "\n",
    "    result={\n",
    "        \"file\": str(file_path),\n",
    "        \"parsed_metadata\": meta,\n",
    "        # SoC (continuous)\n",
    "        \"predicted_SoC_percent\": float(soc_mean),\n",
    "        \"SoC_std_estimate\": float(soc_std),\n",
    "        \"soc_model_chosen\": soc_model_name,\n",
    "        \"SoC_probabilities\": soc_probs,  # may be None for regression\n",
    "        # SoH\n",
    "        \"predicted_SoH_percent\": float(soh_mean),\n",
    "        \"SoH_std_estimate\": float(soh_std),\n",
    "        \"raw_model_mean\": float(soh_mean_raw),\n",
    "        \"raw_model_std\": float(soh_std_raw),\n",
    "        \"shape_model_mean\": None if shape_model is None else float(shape_soh_mean),\n",
    "        \"shape_model_std\": None if shape_model is None else float(shape_soh_std),\n",
    "        # RUL\n",
    "        \"cycles_per_percent_used\": float(cpp),\n",
    "        \"cycles_to_target\": float(cycles_to_target),\n",
    "        \"cycles_to_lower\": float(cycles_to_lower),\n",
    "        \"decision_threshold_percent\": cfg.DECISION_SOH_PERCENT,\n",
    "        \"lower_threshold_percent\": cfg.ILLUSTRATIVE_MIN_SOH,\n",
    "        # Meta\n",
    "        \"feature_version\": bundle.get(\"feature_version\"),\n",
    "        \"soh_model_chosen\": model_name,\n",
    "        # OOD\n",
    "        \"OOD_mahal\": None if mahal_dist is None else float(mahal_dist),\n",
    "        \"OOD_gp_ard_norm\": None if ard_norm is None else float(ard_norm),\n",
    "        \"OOD_flag\": bool(ood_flag)\n",
    "    }\n",
    "    return result, ood_flag, cycles_to_target, cycles_to_lower\n",
    "\n",
    "# =========================\n",
    "# 16. MAIN\n",
    "# =========================\n",
    "def main():\n",
    "    if cfg.VERBOSE:\n",
    "        print(\"Configuration:\\n\", json.dumps(to_jsonable(asdict(cfg)), indent=2))\n",
    "\n",
    "    # Directory assertions\n",
    "    assert cfg.EIS_DIR.exists(), f\"EIS_DIR missing: {cfg.EIS_DIR}\"\n",
    "    if cfg.REFINE_SOH_WITH_CAPACITY:\n",
    "        assert cfg.CAP_DIR.exists(), f\"CAP_DIR missing: {cfg.CAP_DIR}\"\n",
    "\n",
    "    # Capacity + dynamic CPP\n",
    "    cap_df = load_capacity_info(cfg.CAP_DIR)\n",
    "    if cap_df.empty:\n",
    "        if cfg.VERBOSE:\n",
    "            print(\"[INFO] No / empty capacity data -> fallback Cpp.\")\n",
    "        cpp_map, global_cpp = {}, cfg.CPP_FALLBACK\n",
    "    else:\n",
    "        cpp_map, global_cpp = build_cpp_map(cap_df)\n",
    "        if cfg.VERBOSE:\n",
    "            print(f\"[CPP] dynamic cells={len(cpp_map)} global_cpp_median={global_cpp:.2f}\")\n",
    "\n",
    "    bundle_path = cfg.MODEL_DIR/\"eis_soc_soh_phys_models.joblib\"\n",
    "    if bundle_path.exists() and not cfg.FORCE_RETRAIN:\n",
    "        if cfg.VERBOSE:\n",
    "            print(f\"[LOAD] Using existing model bundle: {bundle_path}\")\n",
    "        bundle = load_bundle()\n",
    "    else:\n",
    "        if cfg.VERBOSE:\n",
    "            print(\"[TRAIN] Building dataset & training models...\")\n",
    "        meta_df, X_raw, shape_bundle, y_soc, y_soh = build_dataset(cfg.EIS_DIR, cap_df)\n",
    "        if cfg.VERBOSE:\n",
    "            print(f\"[TRAIN] Samples={X_raw.shape[0]} Features={X_raw.shape[1]} Cells={meta_df.CellID.nunique()}\")\n",
    "        bundle = train_models(meta_df, X_raw, shape_bundle, y_soc, y_soh)\n",
    "\n",
    "    # Inference\n",
    "    for test_fp in cfg.EIS_TEST_FILES:\n",
    "        print(f\"\\n===== TEST: {test_fp.name} =====\")\n",
    "        if not test_fp.exists():\n",
    "            print(f\"[WARN] Test file not found: {test_fp}\")\n",
    "            continue\n",
    "        try:\n",
    "            result, ood_flag, cyc_target, cyc_lower = predict_file(test_fp, bundle, cpp_map, global_cpp)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Prediction failed for {test_fp.name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        out_plot = cfg.MODEL_DIR / f\"{test_fp.stem}_projection.png\"\n",
    "        plot_projection(\n",
    "            test_fp.stem,\n",
    "            result[\"predicted_SoH_percent\"],\n",
    "            result[\"SoH_std_estimate\"],\n",
    "            result[\"cycles_to_target\"],\n",
    "            result[\"cycles_to_lower\"],\n",
    "            result[\"cycles_per_percent_used\"],\n",
    "            result[\"OOD_flag\"],\n",
    "            out_plot\n",
    "        )\n",
    "\n",
    "        out_json = cfg.MODEL_DIR / f\"{test_fp.stem}_prediction.json\"\n",
    "        with out_json.open(\"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(result, f, indent=2)\n",
    "        print(json.dumps(result, indent=2))\n",
    "        print(f\"[PLOT] Saved: {out_plot}\")\n",
    "        print(f\"[JSON] Saved: {out_json}\")\n",
    "\n",
    "    print(\"\\nDone.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7a5678-572c-498e-9eda-4b75ccaecf76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5c9e5d-8822-4703-89f9-394059eb695f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
